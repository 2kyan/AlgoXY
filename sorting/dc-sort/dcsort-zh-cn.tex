\ifx\wholebook\relax \else
\documentclass[b5paper]{ctexart}
\usepackage[nomarginpar
  %, margin=.5in
]{geometry}

\addtolength{\oddsidemargin}{-0.05in}
\addtolength{\evensidemargin}{-0.05in}
\addtolength{\textwidth}{0.1in}
\usepackage[cn]{../../prelude}

\setcounter{page}{1}

\begin{document}

\title{快速排序和归并排序}

\author{刘新宇
\thanks{{\bfseries 刘新宇 } \newline
  Email: liuxinyu95@gmail.com \newline}
  }

\maketitle
\fi

\markboth{快速排序和归并排序}{基本算法}

\ifx\wholebook\relax
\chapter{快速排序和归并排序}
\numberwithin{Exercise}{chapter}
\fi

人们已证明，基于比较的排序算法的性能上限为$O(n \lg n)$\cite{TAOCP}。本章介绍两种分治排序算法：快速排序和归并排序，性能均可达到$O(n \lg n)$。我们还会介绍它们的若干变形，如自然归并排序，原地归并排序等。

\section{快速排序}
\index{快速排序}

\begin{figure}[htbp]
 \centering
 \includegraphics[scale=0.3]{img/kids}
 \captionsetup{labelformat=empty}
 %\caption{}
 \label{fig:knuth-ssort}
\end{figure}

考虑安排一组小朋友按照个头排队。

\begin{enumerate}
  \item 第一个小朋友举起手。所有比这个小朋友矮的都站到他的左侧去；所有比他高的站到他的右侧去；
  \item 所有站到左侧的小朋友重复这一步骤；站到右侧的也重复这一步骤。
\end{enumerate}

设孩子们的身高为（厘米）：$[102, 100, 98, 95, 96, 99, 101, 97]$。表\ref{tab:kids-sort}描述了这一排队过程。第一步，身高为102厘米的孩子举手。我们称这个小朋友为基准，标以下划线。恰巧他的身高最高。所有人都站到他左侧，如表中第二行所示。此时，身高为102厘米的小朋友站到了最终应站的位置，我们标以引号。第二步，身高为100厘米的孩子举手。身高为98、95、96、99厘米的小朋友站到了他的左侧，而身高为101厘米的小朋友站到了右侧。如表中第三行。第四步，身高为98厘米的小朋友成为了左侧的基准；身高为101厘米的小朋友成为了右侧基准。但右侧那组只有一人，无需继续排序。重复同样的方法，直到所有人都站到最终位置。

\begin{table}[htbp]
\centering
\begin{tabular}{ | c c c c c c c c |}
\hline
\underline{102} & 100 & 98 & 95 & 96 & 99 & 101 & 97 \\
\underline{100} & 98 & 95 & 96 & 99 & 101 & 97 & `102' \\
\underline{98} & 95 & 96 & 99 & 97 & `100' & 101 & `102' \\
\underline{95} & 96 & 97 & `98' & 99 & `100' & `101' & `102' \\
`95' & \underline{96} & 97 & `98' & `99' & `100' & `101' & `102' \\
`95' & `96' & 97 & `98' & `99' & `100' & `101' & `102' \\
`95' & `96' & `97' & `98' & `99' & `100' & `101' & `102' \\
\hline
\end{tabular}
\caption{按身高排队过程}
\label{tab:kids-sort}
\end{table}

我们可以归纳出快速排序的定义。对序列$L$进行排序时：

\begin{itemize}
\item 若$L$为空$[\ ]$，则排序结果为空$[\ ]$；
\item 否则，在$L$中任选一个元素作为基准$p$，然后递归地将$L$中不大于$p$的元素排序，将结果置于$p$的左侧，\underline{同时}将所有大于$p$的元素排序，结果置于右侧。
\end{itemize}

我们说“同时”而不是“然后”。左右两侧的递归排序是并行的。快速排序由霍尔（C. A. R. Hoare）在1960年提出\cite{TAOCP}、\cite{wiki-qs}。我们的定义中并没有说明如何选择基准。这里有多种可能，例如总选择第一个元素作为基准$p$：

\be
\begin{array}{rcl}
sort\ [\ ] & = & [\ ] \\
sort\ (x \cons xs) & = & sort\ [y | y \in xs, y \leq x] \doubleplus [x] \doubleplus sort\ [y | y \in xs, x < y] \\
\end{array}
\ee

我们使用了集合论中的“策梅罗——弗兰克尔”表达式（简称ZF表达式）的列表形式\footnote{以纪念对现代集合论创始人策梅罗（Zermelo）、弗兰克尔（Frankel）。}。一个ZF表达式$\{ a | a \in S, p_1(a), p_2(a), ... \}$表示从集合$S$中选取使得断言$p_1, p_2, ...$都为真的元素（见第一章）。如下面的例子代码：

\lstset{frame = single}
\begin{Haskell}
sort [] = []
sort (x:xs) = sort [y | y<-xs, y <= x] ++ [x] ++ sort [y | y<-xs, x < y]
\end{Haskell}

我们假设按非递减的顺序排序。也可以按照其它规则排序，以适于各种场景，如数字、字符串、或更复杂的内容。为此我们可以把比较条件抽象成参数（见第三章）。我们并不要求比较条件一定是全序，但是至少要满足\textbf{严格弱序}\cite{wiki-total-order}、\cite{wiki-sweak-order}(见第九章)。简单起见，我们仅考虑使用$\leq$作为比较条件。

\subsection{划分}
\index{快速排序!划分（partition）}
在基本快速排序的定义中，我们遍历了两次：第一次获得了所有$\leq x$的元素，第二次获得所有$> x$的元素。可以将它们合并成一次划分过程：

\be
\begin{array}{rcl}
\textit{part}\ p\ [\ ] & = & ([\ ], [\ ]) \\
\textit{part}\ p\ (x \cons xs) & = & \begin{cases}
 p(x): & (x \cons as, bs), \text{其中}: (as, bs) = \textit{part}\ p\ xs \\
 \text{否则}: & (as, x \cons bs) \\
\end{cases} \\
\end{array}
\ee

这样快速排序的定义变为：

\be
\begin{array}{rcl}
sort\ [\ ] & = & [\ ] \\
sort\ (x \cons xs) & = & sort\ as \doubleplus [x] \doubleplus sort\ bs, \text{其中}: (as, bs) = \textit{part}\ (\leq x)\ xs \\
\end{array}
\ee

我们也可以用叠加来定义划分：

\be
\textit{part}\ p\ = foldr\ f\ ([\ ], [\ ])
\ee

其中$f$定义为：

\be
f\ (as, bs)\ x = \begin{cases}
p(x): & (x \cons as, bs) \\
\text{否则}: & (as, x \cons bs) \\
\end{cases}
\ee

使用叠加实现的划分，本质上是向划分结果$(as, bs)$累积的过程。若$p(x)$，则累积$x$到$as$，否则累积到$bs$。这样我们可以实现一个尾递归的划分：

\be
\begin{array}{rcl}
\textit{part}\ p\ [\ ]\ as\ bs & = & (as, bs) \\
\textit{part}\ p\ (x \cons xs)\ as\ bs & = & \begin{cases}
  p(x): & \textit{part}\ p\ xs\ (x \cons as)\ bs \\
  \text{否则}: & \textit{part}\ p\ xs\ as\ (x \cons bs) \\
\end{cases}
\end{array}
\ee

下面的表达式对$(x \cons xs)$进行划分：

\[
(as, bs) = \textit{part}\ (\leq x)\ xs\ [\ ]\ [\ ]
\]

快速排序定义中的连接操作$sort\ as \doubleplus [x] \doubleplus sort\ bs$可以进一步转化为累积形式：

\be
\begin{array}{rcl}
sort\ s\ [\ ] & = & s \\
sort\ s\ (x \cons xs) & = & sort\ (x : sort\ s\ bs)\ as \\
\end{array}
\ee

其中$s$为累积结果。我们传入一个空列表来启动排序：$qsort = sort\ [\ ]$。划分完成时，需要递归地对两个子列表$as$、$bs$排序。我们可以先对$bs$排序，将$x$链接到结果前，作为新的“累积结果”传入后续的排序中。

\begin{Haskell}
sort = sort' []

sort' acc [] = acc
sort' acc (x:xs) = sort' (x : sort' acc bs) as where
  (as, bs) = part xs [] []
  part [] as bs = (as, bs)
  part (y:ys) as bs | y <= x = part ys (y:as) bs
                    | otherwise = part ys as (y:bs)
\end{Haskell}

\subsection{原地排序}
我们接下来考虑如何实现原地划分、排序。图\ref{fig:partition-1-way}描述了这种一次遍历划分的方法\cite{Bentley}\cite{CLRS}。我们从左向右扫描数组。任何时候，数组都由图\ref{fig:partition-1-way} (a)所示的几部分组成：

\begin{figure}[htbp]
   \centering
   \subcaptionbox{划分的不变性质}{
      \begin{tikzpicture}[scale=0.8]
      \draw (0, 0) rectangle (1, 1) node (xl) [pos=.5] {x[l]}
            (1, 0) rectangle (5, 1) node (leq) [pos=.5] {... $\leq p$ ...}
            (5, 0) rectangle (9, 1) node (ge) [pos=.5] {... $> p$ ...}
            (9, 0) rectangle (11, 1) node (rest) [pos=.5] {...?...}
            (11, 0) rectangle (12, 1) node (xu) [pos=.5] {x[u]};
      \fill [black] (5, 0) rectangle (5.1, 1) node (leftbar) [pos=.5] {}
                    (9, 0) rectangle (9.1, 1) node (rightbar) [pos=.5] {};
      \draw (0, 2) node (pivot) {$p = x[l]$}
            (5, 2) node (left) {左边界$L$}
            (9, 2) node (right) {右边界$R$};
      \draw[thick, ->] (pivot) edge (xl)
                       (left) edge [bend right] (leftbar)
                       (right) edge [bend right] (rightbar);
      \end{tikzpicture}} \\
   \subcaptionbox{开始}{
      \begin{tikzpicture}[scale=0.8]
      \draw (-0.5, 0) rectangle (1, 1) node (xl) [pos=.5] {x[l]}
            (1, 0) rectangle (2.5, 1) node (xl1) [pos=.5] {x[l+1]}
            (2.5, 0) rectangle (4, 1) node (rest) [pos=.5] (ai) {...?...}
            (4, 0) rectangle (5, 1) node (xu) [pos=.5] {x[u]};
      \fill [black] (1, 0) rectangle (1.1, 1) node (leftbar) [pos=.5] {};
      \draw (-2, 2) node (pivot) {$p$}
            (0, 2) node (left) {$L$}
            (2, 2) node (right) {$R$};
      \draw[thick, ->] (pivot) edge [bend right] (xl)
                       (left) edge [bend right] (leftbar)
                       (right) edge [bend left] (leftbar);
      \end{tikzpicture}} \\
   \subcaptionbox{结束}{
      \begin{tikzpicture}[scale=0.8]
      \draw (0, 0) rectangle (1, 1) node (xl) [pos=.5] {x[l]}
            (1, 0) rectangle (5, 1) node (leq) [pos=.5] {... $\leq p$ ...}
            (5, 0) rectangle (6, 1) node (xleft) [pos=.5] {x[$L$] }
            (6, 0) rectangle (10, 1) node (ge) [pos=.5] {... $> p$ ...}
            (10, 0) rectangle (11, 1) node (xu) [pos=.5] {x[u]};
      \fill [black] (6, 0) rectangle (6.1, 1) node (leftbar) [pos=.5] {}
                    (11, 0) rectangle (11.1, 1) node (rightbar) [pos=.5] {};
      \draw (0, 2) node (pivot) {$p$}
            (6, 2) node (left) {$L$}
            (12, 2) node (right) {$R$};
      \draw[thick, ->] (pivot) edge (xl)
                       (left) edge [bend right] (leftbar)
                       (right) edge [bend left] (rightbar);
      \draw[thick, <->] (xl) edge [bend right] node [below] {交换} (xleft);
      \end{tikzpicture}} \\
   \caption{用首个元素作基准$p$划分一段数组}
   \label{fig:partition-1-way}
\end{figure}

\begin{itemize}
\item 最左侧为基准$p$。划分结束时，$p$被移动到最终位置；
\item 一段只包含$\leq p$的部分。这一段的右侧边界为$L$；
\item 一段只包含$> p$的部分。这一段的右侧边界为$R$。$L$、$R$之间的元素都大于$p$；
\item $R$后面的元素尚未处理。这部分的元素可能大于或不大于$p$。
\end{itemize}

划分开始时，$L$指向$p$，$R$指向$p$的下一个元素，如图\ref{fig:partition-1-way} (b)所示。然后不断向右移动$R$进行处理，直到$R$越过数组右侧。每次迭代，都比较$R$指向的元素和$p$。若$x[R] > p$，它应位于$L$和$R$之间，我们继续向前移动$R$；否则$x[R] \leq p$，它应该位于$L$左侧。我们将$L$向前移动一步，然后交换$x[L]$和$x[R]$。当$R$越过最后一个位置时，所有的元素都已处理完。$> p$的元素都被移动到了$L$右侧，而其它元素位于$L$左侧。此时我们需要移动$p$，使它位于这两段的中间。为此，我们交换$p$和$x[L]$。如图\ref{fig:partition-1-way} (c)中的双向箭头所示。$L$最终指向$p$，将整个数组分成两部分。我们将$L$作为划分的结果返回。为了方便后继处理，我们将$L$增加1，使得它指向第一个大于$p$的元素。令数组为$A$，待划分区间的上下界为$l, u$，原地划分实现如下：

\begin{algorithmic}[1]
\Function{Partition}{A, l, u}
  \State $p \gets A[l]$  \Comment{基准}
  \State $L \gets l$ \Comment{左侧}
  \For{$R$ in $[l+1, u]$} \Comment{对右侧迭代}
    \If{$p \geq A[R]$}
      \State $L \gets L + 1$
      \State \textproc{Exchange} $A[L] \leftrightarrow A[R]$
    \EndIf
  \EndFor
  \State \textproc{Exchange} $A[L] \leftrightarrow p$
  \State \Return $L + 1$ \Comment{返回划分的位置}
\EndFunction
\end{algorithmic}

表\ref{tab:partition-steps}给出了划分数组$[3, 2, 5, 4, 0, 1, 6, 7]$的步骤。

\begin{table}[htbp]
\centering
\begin{tabular}{|llllllll|l|}
\hline
\underline{3}(l)  & 2(r) & 5 & 4 & 0 & 1 & 6 & 7 & 开始，$p = 3$、$l = 1$、$r = 2$ \\
\underline{3} & 2(l)(r) & 5 & 4 & 0 & 1 & 6 & 7 & $2 < 3$，移动$l$（$r=l$）\\
\underline{3} & 2(l) & 5(r) & 4 & 0 & 1 & 6 & 7 & $5 > 3$, 继续 \\
\underline{3} & 2(l) & 5 & 4(r) & 0 & 1 & 6 & 7 & $4 > 3$, 继续 \\
\underline{3} & 2(l) & 5 & 4 & 0(r) & 1 & 6 & 7 & $0 < 3$ \\
\underline{3} & 2 & 0(l) & 4 & 5(r) & 1 & 6 & 7 & 移动$l$，然后和$r$交换 \\
\underline{3} & 2 & 0(l) & 4 & 5 & 1(r) & 6 & 7 & $1 < 3$ \\
\underline{3} & 2 & 0 & 1(l) & 5 & 4(r) & 6 & 7 & 移动$l$，然后和$r$交换 \\
\underline{3} & 2 & 0 & 1(l) & 5 & 4 & 6(r) & 7 & $6 > 3$，继续 \\
\underline{3} & 2 & 0 & 1(l) & 5 & 4 & 6 & 7(r) & $7 > 3$，继续 \\
1 & 2 & 0 & 3 & 5(l+1) & 4 & 6 & 7 & $r$越过了边界，交换$p$和$l$ \\
\hline
\end{tabular}
\caption{扫描并划分数组} \label{tab:partition-steps}
\end{table}

使用\textproc{Partition}，可以实现快速排序如下：

\begin{algorithmic}[1]
\Procedure{Quick-Sort}{$A, l, u$}
  \If{$l < u$}
    \State $m \gets$ \Call{Partition}{$A, l, u$}
    \State \Call{Quick-Sort}{$A, l, m - 1$}
    \State \Call{Quick-Sort}{$A, m, u$}
  \EndIf
\EndProcedure
\end{algorithmic}

我们在排序时传入数组上下界，如：\textproc{Quick-Sort}($A, 1, |A|$)。如果数组片段为空或只含有一个元素，我们直接返回。

\begin{Exercise}
\Question{改进基本快速排序的定义，除了列表为空外，优化对单元素列表的处理。}
\end{Exercise}

\subsection{性能分析}
\index{快速排序!性能分析}

快速排序在实际应用中性能良好。我们需要使用统计学工具来分析平均情况下的性能。首先分析最好和最坏情况。最好情况下，每次划分都将序列均分。如图\ref{fig:qsort-best}所示，共需要$O(\lg n)$次递归调用。第一层划分一次，处理$n$个元素；第二层划分两次，每次处理$n/2$个元素，总体执行时间为$2 O(n/2) = O(n)$。第三层划分四次，每次处理$n/4$个元素，总体执行时间也是$O(n)$……最后一层总共有$n$个片段，每个片段一个元素，总时间也是$O(n)$。将所有层的执行时间相加，得到快速排序在最好情况下的性能为$O(n \lg n)$。

\begin{figure}[htbp]
 \centering
 \includegraphics[scale=0.55]{img/qsort-best}
 \caption{最好情况，每次均分。}
 \label{fig:qsort-best}
\end{figure}

最坏情况下，划分极不平衡。一部分长$O(1)$，另一部分的长$O(n)$。递归的深度退化为$O(n)$。用图来描述，最好情况下，快速排序过程形成一棵平衡二叉树；最坏情况下，形成一棵极不平衡的树，每个节点都只有一棵子树，另一棵子树为空。二叉树退化成了一个长度为$O(n)$的链表。而在每一层中，所有的元素都被处理，因此最坏情况下的性能为$O(n^2)$，这和插入排序、选择排序的性能相当。我们可以考虑几种特殊的最坏情况，例如大量元素都相等导致划分结果不平衡。另外已序序列也导致不平衡划分。还有其它一些情况导致性能下降，不存在一种方法可以完全避免最坏情况。

\subsubsection{平均情况\texorpdfstring{$\bigstar$}{★}}
\index{快速排序!平均情况分析}

快速排序在平均情况下性能良好。即使每次划分总得到长度比为1:9的两部分，性能仍然为$O(n \lg n)$\cite{CLRS}。我们给出两种方法分析快速排序在平均情况下的复杂度。第一种方法利用比较操作的次数来考量性能\cite{CLRS}。在选择排序中，任何两个元素都进行了比较。快速排序避免了很多不必要的比较。考虑划分列表$[a_1, a_2, a_3, ..., a_n]$，选择$a_1$作为基准，划分结果产生两个子列表$A = [x_1, x_2, ..., x_k]$和$B = [y_1, y_2, ..., y_{n-k-1}]$。在后继的排序过程中，$A$中任何元素都不再和$B$中的任何元素进行比较。令最终排序的结果为$[a_1, a_2, ..., a_n]$，我们有：若$a_i < a_j$，当且仅当存在某一元素$a_k$满足$a_i < a_k < a_j$，并且$a_k$在$a_i$或$a_j$之前被选为基准时，我们不再对$a_i$和$a_j$进行比较。也就是说，若$a_i$与$a_j$进行比较，则要么$a_i$、要么$a_j$一定在所有$a_{i+1} < a_{i+2} < ... < a_{j-1}$之前被选为基准。令$P(i, j)$代表$a_i$和$a_j$进行比较的概率，我们有：

\be
P(i, j) = \frac{2}{j - i + 1}
\ee

全部比较操作的总数可以这样得到：

\be
C(n) = \sum_{i=1}^{n-1}\sum_{j=i+1}^{n} P(i, j)
\ee

如果我们比较了$a_i$和$a_j$，在接下来的快速排序中，就不再比较$a_j$和$a_i$，并且元素$a_i$永远不会和自己进行比较。因此在上式中，$i$的上限为$n-1$，$j$的下限为$i+1$。将概率代入得：

\be
\begin{array}{rl}
C(n) & = \displaystyle \sum_{i=1}^{n-1}\sum_{j = i+1}^{n} \frac{2}{j - i + 1} \\
     & = \displaystyle \sum_{i=1}^{n-1}\sum_{k=1}^{n-i} \frac{2}{k+1} \\
\end{array}
\ee

使用调和级数\cite{wiki-harmonic}。

\[
H_n = 1 + \frac{1}{2} + \frac{1}{3} + .... = \ln n + \gamma + \epsilon_n
\]

因此：

\be
C(n) = \sum_{i=1}^{n-1} O(\lg n) = O(n \lg n)
\ee

第二种分析方法利用递归。令列表长度$n$，划分后得到两个长度为$i$和$n-i-1$的部分。划分过程比较基准$p$和每个元素，它自身用时$cn$。我们有如下递归关系：

\be
T(n) = T(i) + T(n-i-1) + c n
\ee

其中$T(n)$是对长度为$n$的列表进行快速排序所用的时间。$i$以相同的概率在$0, 1, ..., n-1$中取值。对上述等式取数学期望：

\be
\renewcommand*{\arraystretch}{1.5}
\begin{array}{rl}
T(n) & = E(T(i)) + E(T(n-i-1)) + c n \\
     & = \displaystyle \frac{1}{n} \sum_{i=0}^{n-1}T(i) + \frac{1}{n} \sum_{i=0}^{n-1}T(n-i-1) + cn \\
     & = \displaystyle \frac{1}{n} \sum_{i=0}^{n-1}T(i) + \frac{1}{n} \sum_{j=0}^{n-1}T(j) + cn \\
     & = \displaystyle \frac{2}{n} \sum_{i=0}^{b-1}T(i) + cn
\end{array}
\ee

两边同时乘以$n$：

\be
n T(n) = 2 \sum_{i=0}^{n-1} T(i) + c n^2
\label{eq:ntn}
\ee

将$n$用$n-1$替换，得到另一等式：

\be
(n-1) T(n-1) = 2 \sum_{i=0}^{n-2} T(i) + c (n-1)^2
\label{eq:n1tn1}
\ee

用式(\ref{eq:ntn})减去式(\ref{eq:n1tn1})消去所有的$T(i)$，其中$0 \leq i < n-1$。

\be
n T(n) = (n + 1) T(n-1) + 2cn - c
\ee

忽略常数$c$，上式简化为：

\be
\frac{T(n)}{n+1} = \frac{T(n-1)}{n} + \frac{2c}{n+1}
\ee

依次代入$n-1$、$n-2$……得到$n-1$个等式。

\[
\frac{T(n-1)}{n} = \frac{T(n-2)}{n-1} + \frac{2c}{n}
\]

\[
\frac{T(n-2)}{n-1} = \frac{T(n-3)}{n-2} + \frac{2c}{n-1}
\]

\[
...
\]

\[
\frac{T(2)}{3} = \frac{T(1)}{2} + \frac{2c}{3}
\]

将所有等式相加，消去左右相同的部分，化简得到一个关于$n$的函数。

\be
\frac{T(n)}{n+1} = \frac{T(1)}{2} + 2c \sum_{k=3}^{n+1} \frac{1}{k}
\ee

利用调和级数，最终的结果为：

\be
O(\frac{T(n)}{n+1}) = O(\frac{T(1)}{2} + 2c \ln n + \gamma + \epsilon_n) = O(\lg n)
\ee

因此

\be
O(T(n)) = O(n \lg n)
\ee

\subsection{改进}
\index{快速排序!改进} \index{快速排序!三分划分}

快速排序性能优异，但在最坏情况下，性能会退化到平方级别。如果数据随机分布，出现最坏情况的概率很低。尽管如此，工程上常常采用一些方法以避免或减少出现最坏情况。我们给出的划分实现\textproc{Partition}在处理大量重复元素时出现性能下降。考虑含有$n$个相等元素的特殊序列$[x, x, ..., x]$：

\begin{enumerate}
\item 基本快速排序：任选一个元素作为基准$p = x$，分割后得到两个序列：$[x, x, ..., x]$，长度为$n-1$，另外一个序列为空。接下来递归地对长为$n-1$的序列排序。总复杂度为$O(n^2)$。
\item 只用严格的$< x$、$> x$进行划分。结果是两个空序列和$n$个等于$x$的元素。接下来的递归只应用到两个空列上并立即结束。结果为$[\ ] \doubleplus [x, x, ..., x] \doubleplus [\ ]$。总复杂度为$O(n)$。
\end{enumerate}

据此，我们对划分进行改进：相对于二分划分，\textbf{三分划分}能更好地处理重复元素。

\be
\begin{array}{rcl}
sort\ [\ ] & = & [\ ] \\
sort\ (x \cons xs) & = & sort\ S \doubleplus sort\ E \doubleplus sort\ G
\end{array}
\ee

其中：

\[
\begin{cases}
S = [ y | y \in xs, y < x ] \\
E = [ y | y \in xs, y = x ] \\
G = [ y | y \in xs, y > x ] \\
\end{cases}
\]

这一实现需要线性时间将三个子列表连接起来。我们可以使用一个累积变量进行改进：$qsort = sort\ [\ ]$。其中：

\be
\begin{array}{rcl}
sort\ A\ [\ ] & = & A \\
sort\ A\ (x \cons xs) & = & sort\ (E \doubleplus sort\ A\ G)\ S \\
\end{array}
\ee

我们将非空列表划分为三个子列表$S, E, G$，其中$E$中元素全相等，无需进一步排序。我们先使用累积变量$A$对$G$排序，将结果连接到$E$的后面，作为新的累积变量再对$S$排序。划分也可以使用累积变量改进：

\be
\begin{array}{rcl}
part\ S\ E\ G\ x\ [\ ] & = & (S, E, G) \\
part\ S\ E\ G\ x\ (y \cons ys) & = & \begin{cases}
  y < x: & (y \cons S, E, G) \\
  y = x: & (S, y \cons E, G) \\
  y > x: & (S, E, y \cons G) \\
  \end{cases} \\
\end{array}
\ee

理查德$\cdot$伯德给出了另一种改进\cite{fp-pearls}，它不立即连接递归排序的结果，而是把排好的子列表保存起来，最终再连接在一起：

\begin{Haskell}
sort :: (Ord a) => [a] -> [a]
sort = concat . (pass [])

pass xss [] = xss
pass xss (x:xs) = step xs [] [x] [] xss where
    step [] as bs cs xss = pass (bs : pass xss cs) as
    step (x':xs') as bs cs xss | x' <  x = step xs' (x':as) bs cs xss
                               | x' == x = step xs' as (x':bs) cs xss
                               | x' >  x = step xs' as bs (x':cs) xss
\end{Haskell}

\index{快速排序!双向扫描}
我们接下来介绍的改进叫做\textbf{双向扫描}，是罗伯特$\cdot$塞奇维克（Robert Sedgewick）给出的\cite{qsort-impl}\cite{Bentley}。使用两个指针$i, j$从左右两侧相向扫描。开始时$i, j$指向数组左右边界，选择最左侧的元素作为基准$p$。然后左指针$i$向右扫描直到遇到一个$\geq p$的元素；另外\footnote{两轮扫描可以并发。}右指针$j$向左扫描直到遇到一个$\leq p$的元素。此时，所有$i$左边的元素都$< p$，所有$j$右边的元素都$> p$。$i$指向一个$\geq p$的元素，而$j$指向一个$\leq p$的元素。如图\ref{fig:partition-2-way} (a)。为了将全部$\leq p$的元素划分到左侧，其余元素划分到右侧，我们交换$i$和$j$指向的两个元素。然后恢复扫描，重复上面的步骤直到$i$和$j$相遇或者交错。在划分的任何时刻，总保持着不变条件：所有$i$左侧的元素（包括$i$）都$\leq p$；所有$j$右侧的元素（包括$j$）都$\geq p$。$i$和$j$之间的元素尚未处理。如图\ref{fig:partition-2-way} (b)。

\begin{figure}[htbp]
   \centering
   \subcaptionbox{指针$i$和$j$停止前进时}{
      \begin{tikzpicture}[scale=0.8]
      \draw (0, 0) rectangle (1, 1) node (xl) [pos=.5] {x[l]}
            (1, 0) rectangle (5, 1) node (leq) [pos=.5] {... $< p$ ...}
            (5, 0) rectangle (6, 1) node (xi) [pos=.5] {x[i]}
            (6, 0) rectangle (8, 1) node (rest) [pos=.5] {... ? ...}
            (8, 0) rectangle (9, 1) node (xj) [pos=.5] {x[j]}
            (9, 0) rectangle (13, 1) node (ge) [pos=.5] {... $> p$ ...};
      \draw (0, 2) node (pivot) {基准$p$}
            (5, 2) node (left) {$\geq p$}
            (8, 2) node (right) {$\leq p$};
      \draw[thick, ->] (pivot) edge (xl)
                       (left) edge [bend right] (xi)
                       (right) edge [bend right] (xj);
      \end{tikzpicture}} \\
   \subcaptionbox{划分不变条件}{
      \begin{tikzpicture}[scale=0.8]
      \draw (0, 0) rectangle (1, 1) node (xl) [pos=.5] {x[l]}
            (1, 0) rectangle (5, 1) node (leq) [pos=.5] {... $\leq p$ ...}
            (5, 0) rectangle (7, 1) node (rest) [pos=.5] {... ? ...}
            (7, 0) rectangle (11, 1) node (ge) [pos=.5] {... $\geq p$ ...};
      \fill [black] (5, 0) rectangle (5.1, 1) node (ibar) [pos=.5] {}
                    (7, 0) rectangle (7.1, 1) node (jbar) [pos=.5] {};
      \draw (0, 2) node (pivot) {基准$p$}
            (5, 2) node (i) {$i$}
            (7, 2) node (j) {$j$};
      \draw[thick, ->] (pivot) edge (xl)
                       (i) edge [bend right] (ibar)
                       (j) edge [bend right] (jbar);
      \end{tikzpicture}} \\
   \caption{双向扫描}
   \label{fig:partition-2-way}
\end{figure}

当$i$、$j$相遇或交错时，我们需要一次额外的交换，将最左侧的基准$p$交换到$j$指向的位置上。然后，我们对划分区间下界$l$和$j$之间的数组片段$A[l ... j)$；$i$和划分区间上界$u$之间的片段$A[i ... u)$进行递归排序。

\begin{algorithmic}[1]
\Procedure{Sort}{$A, l, u$} \Comment{排序区间：$[l, u)$}
  \If{$u - l > 1$} \Comment{包含1个以上的元素}
    \State $i \gets l$, $j \gets u$
    \State $p \gets A[l]$ \Comment{基准}
    \Loop
      \Repeat
        \State $i \gets i + 1$
      \Until{$A[i] \geq p$} \Comment{忽略$i \geq u$的情况}
      \Repeat
        \State $j \gets j - 1$
      \Until{$A[j] \leq p$} \Comment{忽略$j < l$的情况}
      \If{$j < i$}
        \State break
      \EndIf
      \State \textproc{Exchange} $A[i] \leftrightarrow A[j]$
    \EndLoop
    \State \textproc{Exchange} $A[l] \leftrightarrow A[j]$ \Comment{移动$p$}
    \State \Call{Sort}{$A, l, j$}
    \State \Call{Sort}{$A, i, u$}
  \EndIf
\EndProcedure
\end{algorithmic}

\index{快速排序!三路划分}
考虑所有元素都相等的极端情况：数组划分为两段长度相等的子数组，发生了$\dfrac{n}{2}$次交换。由于划分是平衡的，所以总体性能仍然为$O(n \lg n)$，而没有退化。和此前的划分实现对比，这一方法的交换次数更少。它跳过了那些在基准正确一侧的元素不进行处理。我们可以把双向扫描和三路划分结合起来。只对不等于基准的元素进行递归。Jon Bentley和Douglas McIlroy给出了一个方法：如图\ref{fig:partition-3-way} (a)所示，先把所有和基准相等的元素保存在两侧\cite{3-way-part}\cite{opt-qs}。

\begin{figure}[htbp]
   \centering
   \subcaptionbox{三路划分的不变条件。}{
      \begin{tikzpicture}[scale=0.8]
      \draw (0, 0) rectangle (1, 1) node (xl) [pos=.5] {x[l]}
            (1, 0) rectangle (3, 1) node [pos=.5] {... $=$ ...}
            (3, 0) rectangle (5, 1) node [pos=.5] {... $<$ ...}
            (5, 0) rectangle (7, 1) node [pos=.5] {... ? ...}
            (7, 0) rectangle (9, 1) node [pos=.5] {... $>$ ...}
            (9, 0) rectangle (11, 1) node [pos=.5] {... $=$ ...};
      \fill [black] (3, 0) rectangle (3.1, 1) node (pbar) [pos=.5] {}
                    (5, 0) rectangle (5.1, 1) node (ibar) [pos=.5] {}
                    (7, 0) rectangle (7.1, 1) node (jbar) [pos=.5] {}
                    (9, 0) rectangle (9.1, 1) node (qbar) [pos=.5] {};
      \draw (0, 2) node (pivot) {基准}
            (3, 2) node (p) {$p$}
            (5, 2) node (i) {$i$}
            (7, 2) node (j) {$j$}
            (9, 2) node (q) {$q$};
      \draw[thick, ->] (pivot) edge (xl)
                       (p) edge [bend right] (pbar)
                       (i) edge [bend right] (ibar)
                       (j) edge [bend left] (jbar)
                       (q) edge [bend left] (qbar);
      \end{tikzpicture}} \\
   \subcaptionbox{将等于基准的元素交换到中间。}{\hspace{0.1\textwidth}
      \begin{tikzpicture}[scale=0.8]
      \draw (0, 0) rectangle (2, 1) node [pos=.5] {... $<$ ...}
            (2, 0) rectangle (4, 1) node [pos=.5] {... $=$ ...}
            (4, 0) rectangle (6, 1) node [pos=.5] {... $>$ ...};
      \fill [black] (2, 0) rectangle (2.1, 1) node (ibar) [pos=.5] {}
                    (4, 0) rectangle (4.1, 1) node (jbar) [pos=.5] {};
      \draw (2, 2) node (i) {$i$}
            (4, 2) node (j) {$j$};
      \draw[thick, ->] (i) edge [bend right] (ibar)
                       (j) edge [bend left] (jbar);
      \end{tikzpicture}
      \hspace{0.1\textwidth}}
   \caption{三路划分}
   \label{fig:partition-3-way}
\end{figure}

扫描过程仍然是左右相向的。直到$i$遇到$\geq$基准的元素，并且$j$遇到$\leq$基准的元素。此时如果$i$和$j$没有相遇或者交错，我们不仅交换$A[i] \leftrightarrow A[j]$，同时检查$A[i], A[j]$是否等于基准。如果相等，就交换$A[i] \leftrightarrow A[p]$或$A[j] \leftrightarrow A[q]$。在划分结束前，我们需要把所有等于基准的元素从左右交换到中间。交换次数取决于重复元素的个数。如果所有元素唯一，则交换次数为零，不产生任何额外消耗。划分结果如图\ref{fig:partition-3-way} (b)所示。此后，我们只需要对“严格小于”和“严格大于”部分递归。

\begin{algorithmic}[1]
\Procedure{Sort}{$A, l, u$}
  \If{$u - l > 1$}
    \State $i \gets l$, $j \gets u$
    \State $p \gets l$, $q \gets u$ \Comment{指向相等元素的边界}
    \State $pivot \gets A[l]$
    \Loop
      \Repeat
        \State $i \gets i + 1$
      \Until{$A[i] \geq pivot$} \Comment{忽略$i \geq u$的错误处理}
      \Repeat
        \State $j \gets j - 1$
      \Until{$A[j] \leq pivot$} \Comment{忽略$j < l$的错误处理}
      \If{$j \leq i$}
        \State break \Comment{注意和此前算法的不同}
      \EndIf
      \State \textproc{Exchange} $A[i] \leftrightarrow A[j]$
      \If{$A[i] = pivot$} \Comment{处理相等的元素}
        \State $p \gets p + 1$
        \State \textproc{Exchange} $A[p] \leftrightarrow A[i]$
      \EndIf
      \If{$A[j] = pivot$}
        \State $q \gets q - 1$
        \State \textproc{Exchange} $A[q] \leftrightarrow A[j]$
      \EndIf
    \EndLoop
    \If{$i = j \land A[i] = pivot$} \Comment{特殊情况}
      \State $j \gets j - 1$, $i \gets i + 1$
    \EndIf
    \For{$k$ from $l$ to $p$} \Comment{将相等的元素交换到中间}
      \State \textproc{Exchange} $A[k] \leftrightarrow A[j]$
      \State $j \gets j - 1$
    \EndFor
    \For{$k$ from $u-1$ down-to $q$}
      \State \textproc{Exchange} $A[k] \leftrightarrow A[i]$
      \State $i \gets i + 1$
    \EndFor
    \State \Call{Sort}{$A, l, j + 1$}
    \State \Call{Sort}{$A, i, u$}
  \EndIf
\EndProcedure
\end{algorithmic}

双向扫描加三路划分的逻辑变得复杂了，需要仔细处理各种边界条件。此前的单向扫描具有简单、直观的特点。我们考虑直接对它进行改进。首先需要调整不变条件。选择第一个元素作为基准$p$，如图\ref{fig:partition-3-way-lomuto}所示。任何时刻，左侧片段包含$< p$的元素；接下来的片段包含$= p$的元素；最右侧片段包含$> p$的元素。三个片段的边界分别为$i$、$k$、$j$。$[k, j)$之间是尚未扫描的元素。我们从左向右逐一扫描。开始时，$< p$的部分为空；$= p$的部分只有一个元素。$i$指向数组的下界，$k$指向$i$的下一个元素。$> p$的部分也为空，$j$指向数组上界。

\begin{figure}[htbp]
   \centering
      \begin{tikzpicture}[scale=0.8]
      \draw (0, 0) rectangle (2, 1) node [pos=.5] {... $< p$ ...}
            (2, 0) rectangle (4, 1) node [pos=.5] {... $= p$ ...}
            (4, 0) rectangle (6, 1) node [pos=.5] {... ? ...}
            (6, 0) rectangle (8, 1) node [pos=.5] {... $> p$ ...};
      \fill [black] (2, 0) rectangle (2.1, 1) node (ibar) [pos=.5] {}
                    (4, 0) rectangle (4.1, 1) node (kbar) [pos=.5] {}
                    (6, 0) rectangle (6.1, 1) node (jbar) [pos=.5] {};
      \draw (2, 2) node (i) {$i$}
            (4, 2) node (k) {$k$}
            (6, 2) node (j) {$j$};
      \draw[thick, ->] (i) edge [bend right] (ibar)
                       (k) edge [bend right] (kbar)
                       (j) edge [bend left] (jbar);
      \end{tikzpicture}
   \caption{单向扫描三路划分}
   \label{fig:partition-3-way-lomuto}
\end{figure}

划分开始后，我们逐一检查$k$指向的元素。如果它等于$p$，就移动$k$指向下一个元素；如果$> p$，我们将$A[k]$和未处理区间的最后一个元素$A[j-1]$交换，这样$> p$的区间长度就增加一。它的边界$j$向左移动一步。由于不确定移动到位置$k$的元素是否仍然大于$p$，我们需要再次比较，重复上述过程。否则，如果元素$< p$，我们将$A[k]$和$= p$的区间的第一个元素$A[i]$交换。当$k$和$j$相遇时，划分过程结束。

\begin{algorithmic}[1]
\Procedure{Sort}{$A, l, u$}
  \If{$u - l > 1$}
    \State $i \gets l$, $j \gets u$, $k \gets l + 1$
    \State $pivot \gets A[i]$
    \While{$k < j$}
      \While{$pivot < A[k]$}
        \State $j \gets j - 1$
        \State \textproc{Exchange} $A[k] \leftrightarrow A[j]$
      \EndWhile
      \If{$A[k] < pivot$}
        \State \textproc{Exchange} $A[k] \leftrightarrow A[i]$
        \State $i \gets i + 1$
      \EndIf
      \State $k \gets k + 1$
    \EndWhile
    \State \Call{Sort}{$A, l, i$}
    \State \Call{Sort}{$A, j, u$}
  \EndIf
\EndProcedure
\end{algorithmic}

和双向扫描加三路划分相比，这一实现相对简单但需要更多的交换次数。

\subsubsection{最差情况}

虽然三路划分能较好地应对大量重复元素，但仍然无法有效解决一些最差情况。例如，序列中的大部分元素已序时（无论是升序还是降序），划分结果不平衡。图\ref{fig:worst-cases-1}是两种极端情况：$[x_1 < x_2 < ... < x_n]$和$[y_1 > y_2 > ... > y_n]$的划分结果。我们可以给出更多的最差情况，例如$[x_m, x_{m-1}, ..., x_2, x_1, x_{m+1}, x_{m+2}, ... x_n]$，其中$[ x_1 < x_2 < ... < x_n]$，以及$[x_n, x_1, x_{n-1}, x_2, ... ]$。如图\ref{fig:worst-cases-2}所示。

\begin{figure}[htbp]
   \centering
   \subcaptionbox{$[x_1 < x_2 < ... < x_n]$的划分树。$\leq p$的部分总为空。}{\hspace{.3\textwidth} \includegraphics[scale=0.5]{img/unbalanced} \hspace{.3\textwidth}} \\
   \subcaptionbox{$[y_1 > y_2 > ... > y_n]$的划分树，$\geq p$的部分总为空。}{\includegraphics[scale=0.5]{img/unbalanced-2}} \\
   \caption{两种最差情况}
   \label{fig:worst-cases-1}
\end{figure}

\begin{figure}[htbp]
   \centering
   \subcaptionbox{除了第一次划分，其它都不平衡。}{\includegraphics[scale=0.4]{img/unbalanced-3}} \\
   \subcaptionbox{一个之字形的划分树。}{\includegraphics[scale=0.5]{img/unbalanced-zigzag}} \\
   \caption{更多最差情况}
   \label{fig:worst-cases-2}
\end{figure}

这几种最差情况中，选择第一个元素作为基准使得划分结果不平衡，塞奇维克给出了一种改进\cite{qsort-impl}：不在固定的位置上选择基准，而是进行简单的抽样以减小引发不平衡划分的可能性。检查第一个元素、中间元素、末尾元素，选择这三个元素的中数作为基准。在最差情况下，可以保证划分结果中至少含有一个元素。还需要注意一个细节。由于数组索引的字长是有限的，简单用\texttt{(l + u) / 2}计算中间元素索引可能溢出。为此可用\texttt{l + (u - l) / 2}来索引。有两种方法来寻找中数，一种最多需要三次比较操作\cite{3-way-part}；另外一种通过交换将三个元素中的最小值移动到第一个元素的位置，将最大值移动到最后一个位置，将中数移动到中间。

\begin{algorithmic}[1]
\Procedure{Sort}{$A, l, u$}
  \If{$u - l > 1$}
    \State $m \gets \lfloor \frac{l + u}{2} \rfloor$ \Comment{实际中要处理溢出的情况}
    \If{$A[m] < A[l]$} \Comment{确保$A[l] \leq A[m]$}
      \State \textproc{Exchange} $A[l] \leftrightarrow A[m]$
    \EndIf
    \If{$A[u-1] < A[l]$} \Comment{确保$A[l] \leq A[u-1]$}
      \State \textproc{Exchange} $A[l] \leftrightarrow A[u-1]$
    \EndIf
    \If{$A[u-1] < A[m]$} \Comment{确保$A[m] \leq A[u-1]$}
      \State \textproc{Exchange} $A[m] \leftrightarrow A[u-1]$
    \EndIf
    \State \textproc{Exchange} $A[l] \leftrightarrow A[m]$
    \State $(i, j) \gets $ \Call{Partition}{$A, l, u$}
    \State \Call{Sort}{$A, l, i$}
    \State \Call{Sort}{$A, j, u$}
  \EndIf
\EndProcedure
\end{algorithmic}

对上述四种特殊的最差情况，这一实现性能良好。它被称为“三点中值”算法。另一种常见方法是随机选择元素作为基准：

\begin{algorithmic}[1]
\Procedure{Sort}{$A, l, u$}
  \If{$u - l > 1$}
    \State \textproc{Exchange} $A[l] \leftrightarrow A[$ \Call{Random}{$l, u$} $]$
    \State $(i, j) \gets $ \Call{Partition}{$A, l, u$}
    \State \Call{Sort}{$A, l, i$}
    \State \Call{Sort}{$A, j, u$}
  \EndIf
\EndProcedure
\end{algorithmic}

函数\textproc{Random}($l, u$)返回一个在$l$和$u$之间的随机整数$l \leq i < u$。这一位置上的元素被交换到最左侧作为基准。这一方法称为\textbf{随机快速排序}\cite{CLRS}。无论是三点中值还是随机快速排序都不能完全避免最差情况。如果序列随机分布，无论选择第一个还是其它位置上的元素作为基准，在效果上都是相同的。即使在理论上无法避免最差情况，但是这些方法在实际应用中往往能够取得很好的结果。

还有一些工程实践，它们不是着眼于解决划分的最差情况。塞奇维克观察到在序列较短时，快速排序没有明显优势，而插入排序反而更快\cite{Bentley}\cite{3-way-part}。塞奇维克、本特利、麦基尔罗伊测试了不同的序列长度，定义了一个阈值。如果序列中的元素个数少于阈值，就转而使用插入排序。

\begin{algorithmic}[1]
\Procedure{Sort}{$A, l, u$}
  \If{$u - l > $ \textproc{Cut-Off}}
    \State \Call{Quick-Sort}{$A, l, u$}
  \Else
    \State \Call{Insertion-Sort}{$A, l, u$}
  \EndIf
\EndProcedure
\end{algorithmic}

\subsection{快速排序与树排序}

“真正的快速排序”复合应用了多种改进——当序列较短时转为插入排序，就地交换元素，使用三点中值选择基准，双向扫描三路划分。简短的递归定义虽然诠释了快速排序的思路，却没有使用上述任何改进。有人认这样的快速排序本质上是树排序。快速排序和树排序的确有紧密的关系。理查德$\cdot$伯德给出了如何通过“砍伐”概念\footnote{deforestation}，从二叉树排序推导出快速排序\cite{algo-fp}。定义\textit{unfold}函数将一个列表转换为二叉搜索树：

\be
\begin{array}{rcl}
\textit{unfold}\ [\ ] & = & \nil \\
\textit{unfold}\ (x \cons xs) & = & (\textit{unfold}\ [a | a \in xs, a \leq x], x, \textit{unfold}\ [a | a \in xs, a > x]) \\
\end{array}
\ee

和二叉搜索树（见第二章）插入算法相比，\textit{unfold}产生树的方式大相径庭。如果列表为空，结果为一棵空树；否则，将列表中第一个元素$x$作为节点的值，然后递归地构造左右子树。其中左子树是$\leq x$的元素；而右子树是$> x$的元素。而将一棵二叉搜索树通过中序遍历转换成列表的定义为：

\be
\begin{array}{rcl}
\textit{toList}\ \nil & = & [\ ] \\
\textit{toList}\ (l, k, r) & = & \textit{toList}\ l \doubleplus [k] \doubleplus \textit{toList}\ r \\
\end{array}
\ee

我们可以将上述两个函数组合起来，定义出快速排序算法：

\be
\textit{sort} = \textit{toList} \circ \textit{unfold}
\ee

我们先通过\textit{unfold}构造出二叉搜索树，将其作为中间结果送入\textit{toList}得出列表后就可以将树丢弃了。如果将这一临时的中间结果树消除，就得到了基本的快速排序算法\cite{slpj-book-1987}。

\section{归并排序}
\index{归并排序} \index{归并排序!定义}

快速排序在大多数情况下性能优异，但在最差情况下出现退化。即使辅以各种改进也无法完全避免最差情况。归并排序在所有情形下都保证$O(n \lg n)$的复杂度，在算法设计和分析上具有重要意义。归并排序对数组和列表都适用，很多编程环境适用归并排序作为标准的排序方案\footnote{如Haskell, Python和Java}。归并排序本质上也利用了分而治之的策略。它保证划分是严格平衡的，每次将序列从中间位置分开，递归进行排序，然后将两个已序序列归并。

\be
\begin{array}{rcl}
sort\ [\ ] & = & [\ ] \\
sort\ xs & = & merge\ (sort\ as)\ (sort\ bs), \text{其中}: (as, bs) = \textit{halve}\ xs
\end{array}
\ee

其中\textit{halve}将序列对半分开。对于数组，我们可以利用索引直接在中间位置分割：$\textit{splitAt}\ \lfloor \dfrac{|xs|}{2} \rfloor\ xs$。对于列表我们需要线性时间移动到中点进行分割（见第一章），例如：

\be
\textit{splitAt}\ n\ xs = \textit{shift}\ n\ [\ ]\ xs
\ee

其中：

\be
\begin{array}{rcl}
\textit{shift}\ 0\ as\ bs & = & (as, bs) \\
\textit{shift}\ n\ as\ (b \cons bs) & = & \textit{shift}\ (n - 1)\ (b \cons as)\ bs
\end{array}
\ee

对半拆分并不需要保持顺序，我们可以利用奇偶位置分割进行简化。奇偶要么同样多，要么仅相差一个，总能保证平衡。$\textit{halve} = \textit{split}\ [\ ]\ [\ ]$，其中：

\be
\begin{array}{rcl}
\textit{split}\ as\ bs\ [\ ] & = & (as, bs) \\
\textit{split}\ as\ bs\ [x] & = & (x \cons as, bs) \\
\textit{split}\ as\ bs\ (x \cons y \cons xs) & = & \textit{split}\ (x \cons as)\ (y \cons bs)\ xs \\
\end{array}
\ee

我们也可以利用叠加操作进一步简化，如下面的例子程序，每次总把元素$x$添加到$as$上，然后交换$as \leftrightarrow bs$：

\begin{Haskell}
halve = foldr f ([], []) where
  f x (as, bs) = (bs, x : as)
\end{Haskell}

\subsection{归并}
\index{归并排序!归并}

归并的思想如图\ref{fig:merge}所示。考虑两队小孩，已经分别按照身高排队。我们要求孩子们依次通过一扇门，每次一人，按照身高顺序。由于两队都已序，我们比较两个排头，个子较小的一个通过门；然后重复这一步骤，直到任何一队的孩子都已经通过，此后剩下的一队中的孩子们可以逐一通过这扇门。

\begin{figure}[htbp]
 \centering
 \includegraphics[scale=0.3]{img/merge}
 \caption{两队孩子通过一扇门}
 \label{fig:merge}
\end{figure}

\be
\begin{array}{rcl}
\textit{merge}\ [\ ]\ bs & = & bs \\
\textit{merge}\ as\ [\ ] & = & as \\
\textit{merge}\ (a \cons as)\ (b \cons bs) & = & \begin{cases}
  a < b: & a : \textit{merge}\ as\ (b \cons bs) \\
  \text{否则}: & b : \textit{merge}\ (a \cons as)\ bs
  \end{cases}
\end{array}
\ee

对于数组，我们可以直接在中点位置分割，分别递归排序后归并：

\begin{algorithmic}[1]
\Procedure{Sort}{$A$}
  \State $n \gets |A|$
  \If{$n > 1$}
    \State $m \gets \lfloor \dfrac{n}{2} \rfloor$
    \State $X \gets$ \Call{Copy-Array}{$A[1...m]$}
    \State $Y \gets$ \Call{Copy-Array}{$A[m+1...n]$}
    \State \Call{Sort}{$X$}
    \State \Call{Sort}{$Y$}
    \State \Call{Merge}{$A, X, Y$}
  \EndIf
\EndProcedure
\end{algorithmic}

这一方法使用了和数组$A$同样大小的额外空间。这是由于\textproc{Merge}算法不是在原地修改元素的。归并时，我们不断检查数组$X$、$Y$中的元素，选择较小的一个放回数组$A$，接着继续向前处理直到处理完任一数组。最后把另一个数组中的剩余元素添加到$A$中。

\begin{algorithmic}[1]
\Procedure{Merge}{$A, X, Y$}
  \State $i \gets 1, j\gets 1, k\gets 1$
  \State $m \gets |X|, n \gets |Y|$
  \While{$i \leq m$ 且 $j \leq n$}
    \If{$X[i] < Y[j]$}
      \State $A[k] \gets X[i]$
      \State $i \gets i + 1$
    \Else
      \State $A[k] \gets Y[j]$
      \State $j \gets j + 1$
    \EndIf
    \State $k \gets k + 1$
  \EndWhile
  \While{$i \leq m$}
    \State $A[k] \gets X[i]$
    \State $k \gets k + 1$
    \State $i \gets i + 1$
  \EndWhile
  \While{$j \leq n$}
    \State $A[k] \gets Y[j]$
    \State $k \gets k + 1$
    \State $j \gets j + 1$
  \EndWhile
\EndProcedure
\end{algorithmic}

\subsection{性能分析}
\index{归并排序!性能分析}

归并排序分为两步：划分和归并。我们总把序列对半分割。划分树是一棵平衡的二叉树，如图\ref{fig:qsort-best}所示。树的高度为$O(\lg n)$。归并排序的递归深度为$O(\lg n)$。在每一层都进行归并。归并逐一比较两个序列的元素，当其中一个处理完，将另一序列中的剩余元素复制到结果中。归并的复杂度为线性时间。如果序列长度为$n$，记$T(n)$为排序所时间，我们有一下递归关系：

\be
T(n) = T(\dfrac{n}{2}) + T(\dfrac{n}{2}) + c n = 2 T(\dfrac{n}{2}) + c n
\ee

排序时间包含三部分：对前半部分排序$T(\dfrac{n}{2})$，对后半部分排序$T(\dfrac{n}{2})$，归并$c n$，其中$c$是某个常数。解此方程得到结果为$O(n \lg n)$。另外一个重要性能指标是空间复杂度。不同的归并方法空间消耗大相径庭。我们稍后针对几种实现给出空间复杂度分析。对上面的基本实现，每次递归时，都需要和输入数组同样大小的空间，用以复制元素和进一步的递归。递归返回后，这些空间可以释放。最大的空间消耗出现在进入最深一层递归时，为$O(n \lg n)$。

\subsection{改进}
\index{归并排序!分配工作区}

我们接下来将逐步改进函数式和命令式的归并排序算法。前面给出的命令式归并算法比较冗长。我们可以使用正无穷作为sentinel来简化\cite{CLRS}。我们将$\infty$添加到两个待归并的已序数组的末尾\footnote{如果是按照单调非递增顺序排序，则使用$-\infty$}。这样就无需检查数组是否已用完。图\ref{fig:merge-with-sentinel}描述了这一思路。

\begin{figure}[htbp]
 \centering
 \includegraphics[scale=0.8]{img/merge-with-sentinel}
 \caption{使用$\infty$作为sentinels来简化归并}
 \label{fig:merge-with-sentinel}
\end{figure}

\begin{algorithmic}[1]
\Procedure{Merge}{$A, X, Y$}
  \State \Call{Append}{$X, \infty$}
  \State \Call{Append}{$Y, \infty$}
  \State $i \gets 1, j\gets 1$
  \For{$k \gets$ from 1 to $|A|$}
    \If{$X[i] < Y[j]$}
      \State $A[k] \gets X[i]$
      \State $i \gets i + 1$
    \Else
      \State $A[k] \gets Y[j]$
      \State $j \gets j + 1$
    \EndIf
  \EndFor
\EndProcedure
\end{algorithmic}

下面的C语言例子程序实现了这一简化。它将归并算法嵌入到了排序中。\texttt{INF}被定义为一个大常数，类型和\texttt{Key}一致。类型可以预先定义，或者将类型信息通过一个比较函数进行抽象，在将比较函数作为一个参数传入排序算法中。我们在此忽略这些语言细节。

\lstset{language=C}
\begin{lstlisting}
void msort(Key* xs, int l, int u) {
    int i, j, m;
    Key *as, *bs;
    if (u - l > 1) {
        m = l + (u - l) / 2;  //防止int溢出
        msort(xs, l, m);
        msort(xs, m, u);
        as = (Key*) malloc(sizeof(Key) * (m - l + 1));
        bs = (Key*) malloc(sizeof(Key) * (u - m + 1));
        memcpy((void*)as, (void*)(xs + l), sizeof(Key) * (m - l));
        memcpy((void*)bs, (void*)(xs + m), sizeof(Key) * (u - m));
        as[m - l] = bs[u - m] = INF;
        for (i = j = 0; l < u; ++l)
            xs[l] = as[i] < bs[j] ? as[i++] : bs[j++];
        free(as);
        free(bs);
    }
}
\end{lstlisting}

运行这一程序所需的时间远远超过快速排序。除了稍后会介绍的最主要原因外，在归并时反复申请和释放内存也是一个需要改进的地方。内存申请是实际应用程序中的一个常见瓶颈\cite{Bentley}。一个解决方法是一次性申请一个和待排序数组同样大小的空间作为工作区（working area）。此后，对前、后两半部分的递归排序就无需申请额外的空间，而是用工作区来进行归并。最后算法再将工作区内的结果复制回原数组。

下面的算法实现了这一改进的归并排序。

\begin{algorithmic}[1]
\Procedure{Sort}{A}
  \State $B \gets $ \Call{Create-Array}{$|A|$}
  \State \Call{Sort$'$}{$A, B, 1, |A|$}
\EndProcedure
\Statex
\Procedure{Sort$'$}{$A, B, l, u$}
  \If{$u - l > 0$}
    \State $m \gets \lfloor \frac{l + u}{2} \rfloor$
    \State \Call{Sort$'$}{$A, B, l, m$}
    \State \Call{Sort$'$}{$A, B, m + 1, u$}
    \State \Call{Merge$'$}{$A, B, l, m, u$}
  \EndIf
\EndProcedure
\end{algorithmic}

这一算法创建了另一个同样大小的数组，并将其作为一个参数和原待排序数组一同传入\textproc{Sort$'$}算法。在实际的实现中，这一工作区最终需要人工释放，或者使用自动工具如GC（垃圾回收）释放。修改后的归并算法\textproc{Merge$'$}也接受一个工作区参数。

\begin{algorithmic}[1]
\Procedure{Merge$'$}{$A, B, l, m, u$}
  \State $i \gets l, j \gets m + 1, k \gets l$
  \While{$i \leq m \land j \leq u$}
    \If{$A[i] < A[j]$}
      \State $B[k] \gets A[i]$
      \State $i \gets i + 1$
    \Else
      \State $B[k] \gets A[j]$
      \State $j \gets j + 1$
    \EndIf
    \State $k \gets k + 1$
  \EndWhile
  \While{$i \leq m$}
    \State $B[k] \gets A[i]$
    \State $k \gets k + 1$
    \State $i \gets i + 1$
  \EndWhile
  \While{$j \leq u$}
    \State $B[k] \gets A[j]$
    \State $k \gets k + 1$
    \State $j \gets j + 1$
  \EndWhile
  \For{$i \gets$ from $l$ to $u$} \Comment{复制回}
    \State $A[i] \gets B[i]$
  \EndFor
\EndProcedure
\end{algorithmic}

通过这一小改进，归并排序所需要的空间从$O(n \lg n)$降低到$O(n)$。下面的C语言例子程序实现了这一改进。出于示例的目的，我们在一个循环中逐一将归并结果复制会原数组。在实际中通常使用标准库中提供的工具，如\texttt{memcpy}。

\lstset{language=C}
\begin{lstlisting}
void merge(Key* xs, Key* ys, int l, int m, int u) {
    int i, j, k;
    i = k = l; j = m;
    while (i < m && j < u)
        ys[k++] = xs[i] < xs[j] ? xs[i++] : xs[j++];
    while (i < m)
        ys[k++] = xs[i++];
    while (j < u)
        ys[k++] = xs[j++];
    for(; l < u; ++l)
        xs[l] = ys[l];
}

void msort(Key* xs, Key* ys, int l, int u) {
    int m;
    if (u - l > 1) {
        m = l + (u - l) / 2;
        msort(xs, ys, l, m);
        msort(xs, ys, m, u);
        merge(xs, ys, l, m, u);
    }
}

void sort(Key* xs, int l, int u) {
    Key* ys = (Key*) malloc(sizeof(Key) * (u - l));
    kmsort(xs, ys, l, u);
    free(ys);
}
\end{lstlisting}

改进后的程序运行速度明显加快。在我的测试计算机上，对100000个随机产生的元素排序时，速度能够提升20\%到25\%。


\section{原地归并排序}
\index{归并排序!原地归并排序}

命令式归并排序的一个主要缺点是需要额外的空间以进行归并，不带优化的基本实现在高峰时需要$O(n \lg n)$的空间，使用工作区优化后也仍然需要$O(n)$的空间。

这使得人们去探索原地归并排序，通过复用原待排序数组而不申请额外空间。本节中，我们将介绍实现原地归并排序的一些解法。

\subsection{死板的原地归并}
\index{归并排序!死板的原地归并}

第一个想法很直观。如图\ref{fig:merge-in-place-naive}所示，子数组$A$和$B$已排序好，当进行原地归并时，我们规定一个不变性质，令$i$之前的所有元素为已归并完成的部分，它们满足非递减的顺序；每次比较第$i$个元素和第$j$个元素。如果第$i$个元素小于第$j$个元素，就将$i$向前移动一步。这种情况比较简单；否则，说明第$j$个元素应该放入下一个归并结果中，位置在$i$之前。为了达到这一点，所有$i$和$j$之间的元素，包括第$i$个元素，都要向后移动一个位置。我们重复这一步骤，直到所有$A$和$B$中的元素都置于正确的位置。

\begin{figure}[htbp]
 \centering
      \begin{tikzpicture}[scale=0.8]
      \draw (0, 0) rectangle (3, 1) node [pos=.5] {已归并部分}
            (3, 0) rectangle (4, 1) node [pos=.5] {xs[i]}
            (4, 0) rectangle (8, 1) node (subA) [pos=.5] {...已序子序列A...}
            (8, 0) rectangle (9, 1) node (xsj) [pos=.5] {xs[j]}
            (9, 0) rectangle (13, 1) node [pos=.5] {...已序子序列B...};
      \draw[thick, ->] (subA) edge [bend right=45] node [below] {若xs[i] < xs[j]则shift子序列A} (xsj);
      \end{tikzpicture}
 \caption{死板原地归并}
 \label{fig:merge-in-place-naive}
\end{figure}

\begin{algorithmic}[1]
\Procedure{Merge}{$A, l, m, u$}
  \While{$l \leq m \land m \leq u$}
    \If{$A[l] < A[m]$}
      \State $l \gets l + 1$
    \Else
      \State $x \gets A[m]$
      \For{$i \gets m $ down-to $l+1$} \Comment{Shift}
        \State $A[i] \gets A[i-1]$
      \EndFor
      \State $A[l] \gets x$
    \EndIf
  \EndWhile
\EndProcedure
\end{algorithmic}

但是，这一死板的解法使得归并排序的性能退化为平方级$O(n^2)$。这是因为数组的移动是一个线性时间的操作，它和第一个子数组中尚未归并的元素个数成正比。

依照这一方法实现的的C语言例子程序运行速度很慢，对10000个随机生成的元素排序时，它消耗的时间比前面给出的程序多12倍。

\lstset{language=C}
\begin{lstlisting}
void naive_merge(Key* xs, int l, int m, int u) {
    int i; Key y;
    for(; l < m && m < u; ++l)
        if (!(xs[l] < xs[m])) {
            y = xs[m++];
            for (i = m - 1; i > l; --i) /* shift */
                xs[i] = xs[i-1];
            xs[l] = y;
        }
}

void msort3(Key* xs, int l, int u) {
    int m;
    if (u - l > 1) {
        m = l + (u - l) / 2;
        msort3(xs, l, m);
        msort3(xs, m, u);
        naive_merge(xs, l, m, u);
    }
}
\end{lstlisting}

\subsection{原地工作区}
\index{归并排序!原地工作区}

为了能在$O(n \lg n)$时间内实现原地归并排序，当对子数组排序时，必须使用数组剩余的部分作为归并的工作区。对于已经在工作区内的元素，由于稍后也要进行排序，它们不能被覆盖。我们可以修改此前申请同样大小额外空间的程序来实现这一点。思路如下：当我们比较两个已序的子数组的最前面的元素时，如果要将较小的元素放入工作区中的某个位置，我们同时将工作区中的这个元素和选出的较小的元素交换。这样，当归并完成后，原来的两个子数组就保存了此前工作区中存储的内容。如图\ref{fig:merge-workarea}所示。

\begin{figure}[htbp]
 \centering
      \begin{tikzpicture}[scale=0.8]
      \draw (0, 2) rectangle (3, 3) node [pos=.5] {...复用...}
            (3, 2) rectangle (4, 3) node (ai) [pos=.5] {A[i]}
            (4, 2) rectangle (5, 3) node [pos=.5] {...}
            (7, 2) rectangle (10, 3) node [pos=.5] {...复用...}
            (10, 2) rectangle (11, 3) node (bj) [pos=.5] {B[j]}
            (11, 2) rectangle (12, 3) node [pos=.5] {...}
            (0, 0) rectangle (3, 1) node [pos=.5] {...已归并...}
            (3, 0) rectangle (4, 1) node (ck) [pos=.5] {C[k]}
            (4, 0) rectangle (5, 1) node [pos=.5] {...};
      \draw[thick, <->] (ai) edge [bend left] node [above] {比较} (bj)
                        (ai) edge node [right] {若A[i] < B[j]，则swap(A[i], C[k])} (ck);
      \end{tikzpicture}
 \caption{归并时不覆盖工作区中的内容}
 \label{fig:merge-workarea}
\end{figure}

在改进的算法中，两个已序的子数组，和用于归并的工作区都是最初的待排序数组中的一部分。归并时需要提供的参数包括：两个已序数组的起始和结束位置，可以用区间来表示它们；另外还需要提供工作区的起始位置。下面的算法使用$[a, b)$来表示左闭右开区间，它包括$a$，但不包括$b$。算法将已序区间$[i, m)$和$[j, n)$归并到从$k$开始的工作区。

\begin{algorithmic}[1]
\Procedure{Merge}{$A, [i, m), [j, n), k$}
  \While{$i < m \land j < n$}
    \If{$A[i] < A[j]$}
      \State \textproc{Exchange} $A[k] \leftrightarrow A[i]$
      \State $i \gets i + 1$
    \Else
      \State \textproc{Exchange} $A[k] \leftrightarrow A[j]$
      \State $j \gets j + 1$
    \EndIf
    \State $k \gets k + 1$
  \EndWhile
  \While{$i < m$}
    \State \textproc{Exchange} $A[k] \leftrightarrow A[i]$
    \State $i \gets i + 1$
    \State $k \gets k + 1$
  \EndWhile
  \While{$j < m$}
    \State \textproc{Exchange} $A[k] \leftrightarrow A[j]$
    \State $j \gets j + 1$
    \State $k \gets k + 1$
  \EndWhile
\EndProcedure
\end{algorithmic}

注意，在归并时必须满足下面的两个限制条件：

\begin{enumerate}
\item 工作区必须在数组的边界内。也就是说，工作区必须足够大，以容纳交换进来的元素而不会引起越界错误；
\item 工作区可以和任何一个已序的子数组存在重叠，但是必须保证尚未归并的元素不会被覆盖。
\end{enumerate}

下面的C语言例子程序实现了这一算法。

\lstset{language=C}
\begin{lstlisting}
void wmerge(Key* xs, int i, int m, int j, int n, int w) {
    while (i < m && j < n)
        swap(xs, w++, xs[i] < xs[j] ? i++ : j++);
    while (i < m)
        swap(xs, w++, i++);
    while (j < n)
        swap(xs, w++, j++);
}
\end{lstlisting}

使用这一算法，我们很容易想出一个解法，能够将数组的一半内容进行归并排序。接下来的问题是，如何处理剩下的一半尚未排序的元素？如图\ref{fig:merge-in-place-start}所示。

\begin{figure}[htbp]
 \centering
      \begin{tikzpicture}[scale=0.8]
      \draw (0, 0) rectangle (3, 1) node [pos=.5] {...未排序...}
            (3, 0) rectangle (6, 1) node [pos=.5] {...已排序...};
      \end{tikzpicture} \\
 \caption{数组中的一半被排序}
 \label{fig:merge-in-place-start}
\end{figure}

一个直观的想法是递归对工作区中的一半内容进行排序，这样就只剩下$\frac{1}{4}$的元素尚未排序了。结果如图\ref{fig:merge-in-place-quater}所示。这里关键的一点是，我们必须在某个时候将已序的$\frac{1}{4}$元素$B$和已序的$\frac{1}{2}$元素$A$归并。

\begin{figure}[htbp]
 \centering
      \begin{tikzpicture}[scale=0.8]
      \draw (0, 0) rectangle (3, 1) node [pos=.5] {未排序的$\frac{1}{4}$部分}
            (3, 0) rectangle (6, 1) node [pos=.5] {已序的$\frac{1}{4}$元素$B$}
            (6, 0) rectangle (12, 1) node [pos=.5] {...已序的$\frac{1}{2}$元素$A$...};
      \end{tikzpicture} \\
 \caption{$A$和$B$必须在某个时刻归并到一起}
 \label{fig:merge-in-place-quater}
\end{figure}

但是，剩余的工作区，其大小可以容纳$\frac{1}{4}$元素，它足够容纳$A$和$B$的归并结果么？不幸的是，在如图\ref{fig:merge-in-place-quater}所示的布局中，这一空间是不够用的。

但是，上述的第二条限制条件启发我们：能否通过某种归并的设计，保证未归并的元素不被覆盖，从而利用工作区和已序子数组的重叠部分来解决这个问题？

实际上，我们可以先不让工作区的后二分之一元素已序，而让前二分之一部分已序，这样工作区就位于两段已序子数组的中间，如图\ref{fig:merge-in-place-setup} (a)所示。这样的安排就使得工作区和子数组$A$产生了重叠\cite{msort-in-place}。

\begin{figure}[htbp]
 \centering
 \subcaptionbox{}{
      \begin{tikzpicture}[scale=0.8]
      \draw (0, 0) rectangle (3, 1) node [pos=.5] {已序的$\frac{1}{4}$元素$B$}
            (3, 0) rectangle (6, 1) node [pos=.5] {工作区}
            (6, 0) rectangle (12, 1) node [pos=.5] {...已序的$\frac{1}{2}$元素$A$...};
      \end{tikzpicture}} \\
 \subcaptionbox{}{
      \begin{tikzpicture}[scale=0.8]
      \draw (0, 0) rectangle (3, 1) node [pos=.5] {工作区  $\frac{1}{4}$}
            (3, 0) rectangle (12, 1) node [pos=.5] {...已归并$\frac{3}{4}$...};
      \end{tikzpicture}} \\
 \caption{利用工作区归并子数组$A$和$B$}
 \label{fig:merge-in-place-setup}
\end{figure}

考虑两种极端情况：

\begin{enumerate}
\item 所有$B$中的元素都小于$A$中的任意元素。这种情况下，归并算法最终将$B$中的全部内容移动到工作区中；而$B$中将包括以前工作区中所保存的内容；由于工作区和$B$的大小相等，因此恰好可以交换它们的内容；
\item 所有$A$中的元素都小于$B$中的任意元素。这种情况下，归并算法不断交换$A$和工作区中的元素。当工作区的前$\frac{1}{4}$区间被$A$中的元素填满后，算法开始覆盖$A$的前一半部分的内容。幸运的是，被覆盖的内容不是未归并的元素。工作区的边界不断向数组的末尾移动，并最终达到最右侧；此后，归并算法开始交换$B$和工作区的内容。最终工作区被移动到了数组的最左侧，如图\ref{fig:merge-in-place-setup} (b)所示。
\end{enumerate}

我们可以重复这一步骤，总是对未排序部分的后二分之一排序，从而将已序结果交换到前一半，而使得新的工作区位于中间。这样就不断将工作区的大小减半，从$\frac{1}{2}$到$\frac{1}{4}$到$\frac{1}{8}$……归并的规模不断下降。当工作区中只剩下一个元素时，我们无须继续排序，因为只含有一个元素的数组自然是已序的。归并只含有一个元素的数组等价于插入元素。实际上，我们可以使用插入排序来处理最后的几个元素。

完整的算法可以描述如下：

\begin{algorithmic}[1]
\Procedure{Sort}{$A, l, u$}
  \If{$u - l > 0$}
    \State $m \gets \lfloor \frac{l + u}{2} \rfloor$
    \State $w \gets l + u - m$
    \State \Call{Sort'}{$A, l, m, w$} \Comment{后半部分包含已序元素}
    \While{$w - l > 1$}
      \State $u' \gets w$
      \State $w \gets \lceil \frac{l + u'}{2} \rceil$ \Comment{保证工作区足够大}
      \State \Call{Sort'}{$A, w, u', l$} \Comment{前半部分包含已序元素}
      \State \Call{Merge}{$A, [l, l + u' - w], [u', u], w$}
    \EndWhile
    \For{$i \gets w$ down-to $l$} \Comment{改用插入排序}
      \State $j \gets i$
      \While{$j \leq u \land A[j] < A[j-1]$}
        \State \textproc{Exchange} $A[j] \leftrightarrow A[j-1]$
        \State $j \gets j + 1$
      \EndWhile
    \EndFor
  \EndIf
\EndProcedure
\end{algorithmic}

为了满足第一个限制条件，我们必须保证工作区足够大以容纳全部交换进来的元素，因此在对后一半排序时，我们总是使用上限取整。我们将包含结束位置的区间信息传入了\textproc{Merge}算法。

接下来，我们需要定义\text{Sort'}算法，它反过来递归调用\text{Sort}来交换工作区和已序部分。

\begin{algorithmic}[1]
\Procedure{Sort'}{$A, l, u, w$}
  \If{$u - l > 0$}
    \State $m \gets \lfloor \frac{l + u}{2} \rfloor$
    \State \Call{Sort}{$A, l, m$}
    \State \Call{Sort}{$A, m+1, u$}
    \State \Call{Merge}{$A, [l, m], [m+1, u], w$}
  \Else \Comment{将所有元素交换到工作区}
    \While{$l \leq u$}
      \State \textproc{Exchange} $A[l] \leftrightarrow A[w]$
      \State $l \gets l + 1$
      \State $w \gets w + 1$
    \EndWhile
  \EndIf
\EndProcedure
\end{algorithmic}

和前面的死板原地归并排序不同，这一方法在归并中并不shift元素。未排序部分的长度不断递减：$\dfrac{n}{2}, \dfrac{n}{4}, \dfrac{n}{8}, ...$，总共需要$O(\lg n)$步完成排序。每次递归对剩余部分的一半排序，然后使用线性时间进行归并。

记对$n$个元素排序所花费的时间为$T(n)$，我们有如下的等式：

\be
T(n) = T(\frac{n}{2}) + c \frac{n}{2} + T(\frac{n}{4}) + c \frac{3n}{4} + T(\frac{n}{8}) + c \frac{7n}{8} + ...
\label{eq:in-place-sort-time}
\ee

对于一半的元素，花费的时间为：

\be
T(\frac{n}{2}) = T(\frac{n}{4}) + c \frac{n}{4} + T(\frac{n}{8}) + c \frac{3n}{8} + T(\frac{n}{16}) + c \frac{7n}{16} + ...
\label{eq:in-place-sort-time-half}
\ee

两式相减(\ref{eq:in-place-sort-time}) - (\ref{eq:in-place-sort-time-half})得：

\[
T(n) - T(\frac{n}{2}) = T(\frac{n}{2}) + c n (\frac{1}{2} + \frac{1}{2} + ... )
\]

共有$\lg n$个$\dfrac{1}{2}$相加，由此得到计算时间的递归关系为：

\[
T(n) = 2 T(\frac{1}{2}) + c n \lg n
\]

使用裂项求和（telescoping）方法解此方程，可以得到结果$O(n \lg^2 n)$。

下面的C语言例子程序给出了这一算法的完整实现，它使用了前面给出的\texttt{wmerge}函数。

\lstset{language=C}
\begin{lstlisting}
void imsort(Key* xs, int l, int u);

void wsort(Key* xs, int l, int u, int w) {
    int m;
    if (u - l > 1) {
        m = l + (u - l) / 2;
        imsort(xs, l, m);
        imsort(xs, m, u);
        wmerge(xs, l, m, m, u, w);
    }
    else
        while (l < u)
            swap(xs, l++, w++);
}

void imsort(Key* xs, int l, int u) {
    int m, n, w;
    if (u - l > 1) {
        m = l + (u - l) / 2;
        w = l + u - m;
        wsort(xs, l, m, w);  //后半部分包含了已序元素。
        while (w - l > 2) {
            n = w;
            w = l + (n - l + 1) / 2; //向上取整
            wsort(xs, w, n, l);  //前半部分包含已序元素。
            wmerge(xs, l, l + n - w, n, u, w);
        }
        for (n = w; n > l; --n) //切换到插入排序
            for (m = n; m < u && xs[m] < xs[m-1]; ++m)
                swap(xs, m, m - 1);
    }
}
\end{lstlisting}

但是，和前面给出的预先分配同等大小的数组用于归并的程序相比，这一程序的运行速度并不快。在我的测试计算机上，对100000个随机产生的元素排序时，它的运行速度要慢60\%，这主要是由于大量的交换操作造成的。

\subsection{原地归并排序vs.链表归并排序}
\index{归并排序!链表归并排序}

原地归并排序仍然是一个活跃的研究领域。减少归并所需的额外空间是有代价的，它增加了归并排序算法的复杂程度。但是，如果待排序的序列不是存储在数组中，而是用链表来表示，归并就无需额外的空间。如前面的奇偶归并排序算法所示。

为了对比，我们可以给出一个纯命令式的链表归并排序实现。链表节点可以定义为一个结构，如下面的C语言例子所示：

\lstset{language=C}
\begin{lstlisting}
struct Node {
    Key key;
    struct Node* next;
};
\end{lstlisting}

我们可以定义一个辅助函数用于节点连接。设待连接的链表不为空，下面的C语言例子程序实现了连接函数。

\lstset{language=C}
\begin{lstlisting}
struct Node* link(struct Node* x, struct Node* ys) {
    x->next = ys;
    return x;
}
\end{lstlisting}

为了实现命令式的奇偶分割，我们初始化两个空的子列表。然后遍历待分割的列表。每次迭代，我们将当前的节点连接到第一个子列表的前面，然后交换两个子列表，这样下次迭代时，节点就会连接到第二个子列表的前面。这一方法可以描述如下：

\begin{algorithmic}[1]
\Function{Split}{$L$}
  \State $(A, B) \gets (\phi, \phi)$
  \While{$L \neq \phi$}
    \State $p \gets L$
    \State $L \gets $ \Call{Next}{$L$}
    \State $A \gets $ \Call{Link}{$p, A$}
    \State \textproc{Exchange} $A \leftrightarrow B$
  \EndWhile
  \State \Return $(A, B)$
\EndFunction
\end{algorithmic}

下面的C语言例子程序实现了这一分割算法，并将其嵌入到排序函数中。

\lstset{language=C}
\begin{lstlisting}
struct Node* msort(struct Node* xs) {
    struct Node *p, *as, *bs;
    if (!xs || !xs->next) return xs;

    as = bs = NULL;
    while(xs) {
        p = xs;
        xs = xs->next;
        as = link(p, as);
        swap(as, bs);
    }
    as = msort(as);
    bs = msort(bs);
    return merge(as, bs);
}
\end{lstlisting}

接下来需要实现链表的命令式归并算法。思路和数组的归并类似。不断比较两个列表的第一个元素，选择较小的附加到结果列表的末尾。当任一列表变空时，将另外一个列表连接到结果的后面，而无需逐一复制。结果列表在初始化时需要额外的判断，这是因为表头要指向两个列表中首元素较小的一个。一种简化处理是使用一个dummy的sentinel的表头，最后在返回结果前将它去掉。下面的例子程序给出了详细的实现。

\lstset{language=C}
\begin{lstlisting}
struct Node* merge(struct Node* as, struct Node* bs) {
    struct Node s, *p;
    p = &s;
    while (as && bs) {
        if (as->key < bs->key) {
            link(p, as);
            as = as->next;
        }
        else {
            link(p, bs);
            bs = bs->next;
        }
        p = p->next;
    }
    if (as)
        link(p, as);
    if (bs)
        link(p, bs);
    return s.next;
}
\end{lstlisting}

\begin{Exercise}
\begin{itemize}
\item 证明原地归并排序的性能为$O(n \lg n)$。
\end{itemize}
\end{Exercise}

\section{自然归并排序}
\index{归并排序!自然归并排序}

Knuth给出了另外一种方法来实现分而治之的归并排序。整个过程如同从两端点燃一支蜡烛\cite{TAOCP}，称为自然归并排序算法。

\begin{figure}[htbp]
 \centering
 \includegraphics[scale=0.3]{img/burn-candle-2-ends}
 \caption{从两端向中间燃烧的蜡烛}
 \label{fig:burn-candle}
\end{figure}

对于任何序列，可以在任何位置开始找到一个非递减子序列。作为一个特殊情况，我们总可以在最左侧找到这样的子序列。下表给出了一些例子，非递减子序列用下划线标出。

\begin{table}[htbp]
\centering
\begin{tabular}{ | l |}
\hline
\underline{15} , 0, 4, 3, 5, 2, 7, 1, 12, 14, 13, 8, 9, 6, 10, 11 \\
\underline{8, 12, 14}, 0, 1, 4, 11, 2, 3, 5, 9, 13, 10, 6, 15, 7 \\
\underline{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15} \\
\hline
\end{tabular}
\caption{非递减子序列的例子} %\label{}
\end{table}

表中的第一行描述了最差的情况，第二个元素小于第一个，因此非递减子序列长度为一，只包含第一个元素；表中的最后一行描述了最好的情况，整个序列已序，非递减子序列包含全部元素；表中的第二行描述了通常的情况。

对称地，我们同样总是可以从序列的右端向左找到一个非递减子序列。于是，我们可以将两个非递减子序列，一个从头部开始，一个从尾部开始，归并成一个更长的序列。这一思路的最大优点是，我们可以利用子序列元素间的自然顺序，而无需递归排序。

\begin{figure}[htbp]
 \centering
 \includegraphics[scale=0.8]{img/nature-merge-sort}
 \caption{自然归并排序}
 \label{fig:nature-merge-sort}
\end{figure}

图\ref{fig:nature-merge-sort}描述了这一思路。算法开始时，我们从两侧扫描序列，分别找到最长的非递减子序列。然后这两个子序列被归并到一个工作区。归并的结果从工作区的头部依次放置。接着，我们重复这一步骤，继续从两侧向中心进行扫描。这一次，我们将两个已序子序列的结果归并到工作区的右侧，从右向左依次放置。这样的布局可以方便下一轮的扫描。当所有的元素都被扫描并归并到工作区后，我们转而对工作区内的元素进行扫描，而使用原数组作为工作区。每轮都进行这样的切换。最后如有必要，我们将所有的元素从工作区复制到原数组。

唯一的问题是何时结束这一算法。当开始新一轮的扫描时，如果发现最长的非递减子列表一直伸展到数组的末尾，也就是说整个序列已序，此时排序过程结束。

由于这样的归并方式，从头尾两路处理待排序数组，并且使用了子序列的自然元素顺序，它被称为\underline{两路自然归并排序}。实现这一算法时需要仔细处理。图\ref{fig:nature-msort-invariant}描述了自然归并排序时的不变性质（invariant）。任何时候，标记$a$之前的元素和标记$d$之后的元素都已被扫描和归并了。我们要将非递减子序列$[a, b)$向右扩展到最长，同时，要将子序列$[c, d)$向左扩展到最长。工作区的不变性质如图中的第二行所示。$f$之前的元素和$r$之后的元素都已经处理过（它们可能包含若干已序的子序列）。奇数轮时（第1、3、5……轮），我们将子序列$[a, b)$和$[c, d)$从$f$起向右归并；偶数轮时（第2、4、6……轮），我们将子序列从$r$起向左归并。

\captionsetup[subfigure]{labelformat=empty, margin=10pt}
\begin{figure}[htbp]
 \centering
   \subcaptionbox{}{
      \begin{tikzpicture}[scale=0.8]
      \draw (0, 0) rectangle (3, 1) node [pos=.5] {...已扫描...}
            (3, 0) rectangle (6, 1) node [pos=.5] {...$span [a, b)$...}
            (6, 0) rectangle (8, 1) node [pos=.5] {...?...}
            (8, 0) rectangle (11, 1) node [pos=.5] {...$span [c, d)$...}
            (11, 0) rectangle (14, 1) node [pos=.5] {...已扫描...};
      \fill [black] (3, 0) rectangle (3.1, 1) node (abar) [pos=.5] {}
                    (6, 0) rectangle (6.1, 1) node (bbar) [pos=.5] {}
                    (8, 0) rectangle (8.1, 1) node (cbar) [pos=.5] {}
                    (11, 0) rectangle (11.1, 1) node (dbar) [pos=.5] {};
      \draw (3, 2) node (a) {a}
            (6, 2) node (b) {b}
            (8, 2) node (c) {c}
            (11, 2) node (d) {d};
      \draw[thick, ->] (a) edge [bend right] (abar)
                       (b) edge [bend right] (bbar)
                       (c) edge [bend left] (cbar)
                       (d) edge [bend left] (dbar);
      \end{tikzpicture}} \\
    \subcaptionbox{}{
      \begin{tikzpicture}[scale=0.8]
      \draw (0, 0) rectangle (3, 1) node [pos=.5] {...已归并...}
            (3, 0) rectangle (8, 1) node [pos=.5] {...未使用的单元...}
            (8, 0) rectangle (11, 1) node [pos=.5] {...已归并...};
      \fill [black] (3, 0) rectangle (3.1, 1) node (fbar) [pos=.5] {}
                    (8, 0) rectangle (8.1, 1) node (rbar) [pos=.5] {};
      \draw (3, 2) node (f) {f}
            (8, 2) node (r) {r};
      \draw[thick, ->] (f) edge [bend right] (fbar)
                       (r) edge [bend right] (rbar);
      \end{tikzpicture}} \\
 \caption{自然归并排序时的不变性质}
 \label{fig:nature-msort-invariant}
\end{figure}
\captionsetup[subfigure]{labelformat=parens}

在命令式环境中，序列用数组保存。在排序开始前，我们申请和数组同样大小的空间作为工作区。指针$a$和$b$一开始指向最左侧，指针$c$和$d$指向最右侧。指针$f$指向工作区的开头，$r$指向工作区的结尾。

\begin{algorithmic}[1]
\Function{Sort}{$A$}
  \If{$|A| > 1$}
    \State $n \gets |A|$
    \State $B \gets$ \Call{Create-Array}{$n$}  \Comment{创建工作区}
    \Loop
      \State $[a, b) \gets [1, 1)$
      \State $[c, d) \gets [n+1, n+1)$
      \State $f \gets 1, r \gets n$ \Comment{指向工作区首尾的front和rear指针}
      \State $t \gets $ False \Comment{从front归并还是从rear归并}
      \While{$b < c$} \Comment{存在需要扫描的元素}
        \Repeat \Comment{扩展$[a, b)$}
          \State $b \gets b + 1$
        \Until{$b \geq c \lor A[b] < A[b-1]$}

        \Repeat \Comment{扩展$[c, d)$}
          \State $c \gets c - 1$
        \Until{$c \leq b \lor A[c-1] < A[c]$}

        \If{$c < b$} \Comment{避免overlap}
          \State $c \gets b$
        \EndIf

        \If{$b - a \geq n$} \Comment{若$[a, b)$扩展到整个数组则结束}
          \State \Return $A$
        \EndIf

        \If{$t$} \Comment{从front归并}
          \State $f \gets$ \Call{Merge}{$A, [a, b), [c, d), B, f, 1$}
        \Else \Comment{从rear归并}
          \State $r \gets$ \Call{Merge}{$A, [a, b), [c, d), B, r, -1$}
        \EndIf
        \State $a \gets b, d \gets c$
        \State $t \gets \lnot t$ \Comment{切换归并的方向}
      \EndWhile
      \State \textproc{Exchange} $A \leftrightarrow B$ \Comment{切换工作区}
    \EndLoop
  \EndIf
  \State \Return $A$
\EndFunction
\end{algorithmic}

归并算法和此前给出的类似，主要区别在于我们需要将归并的方向作为参数传入。

\begin{algorithmic}[1]
\Function{Merge}{$A, [a, b), [c, d), B, w, \Delta$}
  \While{$a < b \land c < d$}
    \If{$A[a] < A[d-1]$}
      \State $B[w] \gets A[a]$
      \State $a \gets a + 1$
    \Else
      \State $B[w] \gets A[d-1]$
      \State $d \gets d - 1$
    \EndIf
    \State $w \gets w + \Delta$
  \EndWhile
  \While{$a < b$}
    \State $B[w] \gets A[a]$
    \State $a \gets a + 1$
    \State $w \gets w + \Delta$
  \EndWhile
  \While{$c < d$}
    \State $B[w] \gets A[d-1]$
    \State $d \gets d - 1$
    \State $w \gets w + \Delta$
  \EndWhile
  \State \Return $w$
\EndFunction
\end{algorithmic}

下面的C语言例子程序实现了两路自然归并排序算法。这里我们没有释放工作区所申请的内存。

\lstset{language=C}
\begin{lstlisting}
int merge(Key* xs, int a, int b, int c, int d, Key* ys, int k, int delta) {
    for(; a < b && c < d; k += delta )
        ys[k] = xs[a] < xs[d-1] ? xs[a++] : xs[--d];
    for(; a < b; k += delta)
        ys[k] = xs[a++];
    for(; c < d; k += delta)
        ys[k] = xs[--d];
    return k;
}

Key* sort(Key* xs, Key* ys, int n) {
    int a, b, c, d, f, r, t;
    if(n < 2)
        return xs;
    for(;;) {
        a = b = 0;
        c = d = n;
        f = 0;
        r = n-1;
        t = 1;
        while(b < c) {
            do {      //扩展[a, b)
                ++b;
            } while( b < c && xs[b-1] <= xs[b] );
            do{      //扩展[c, d)
                --c;
            } while( b < c && xs[c] <= xs[c-1] );
            if( c < b )
                c = b;   //消除可能的重叠
            if( b - a >= n)
                return xs;          //已序
            if( t )
                f = merge(xs, a, b, c, d, ys, f, 1);
            else
                r = merge(xs, a, b, c, d, ys, r, -1);
            a = b;
            d = c;
            t = !t;
        }
        swap(&xs, &ys);
    }
    return xs;
}
\end{lstlisting}

自然归并排序的性能和子数组中元素间的顺序相关。但在实际中，即使在最坏情况下，自然归并排序的性能仍然很好。假设我们运气很差，在第一轮扫描数组时，非递减子序列的长度总为1。这轮扫描结束后，工作区中归并的已序子数组的长度为2。假设接下来一轮运气仍然很差，但是此前的结果保证了非递减子序列的长度不可能小于2。这一轮过后，工作区将包含长度为4的归并结果……重复这一过程，每一轮后，归并的已序子数组的长度都加倍，因此最多进行$O(\lg n)$轮扫描和归并。在每一轮中，所有的元素都被扫描。这一最坏情况下的性能仍然为$O(n \lg n)$。我们稍后在介绍自底向上的归并排序时，会再次解释这一有趣的现象。

在纯函数环境中，由于底层的数据结构是单向链表，我们无法从首尾两端扫描列表。因此需要用别的方法来实现自然归并排序。

由于待排序列表总是由若干非递减子列表构成，我们可以每次取两个子列表，归并出一个更长的列表。我们重复取出列表，然后归并。这样非递减子列表的数目不断减半，最后将得到唯一的列表，也就是最终排序的结果。这一过程可以形式化为下面的等式。

\be
sort(L) = sort'(group(L))
\ee

其中函数$group(L)$将列表中的元素分组成非递减子列表。它可以被描述如下，前面两条为边界条件。

\begin{itemize}
\item 若列表为空，则结果为一个列表，它包含一个空列表作为唯一的元素；
\item 若列表中只含有一个元素，结果为一个列表，它包含一个只含有一个元素的列表；
\item 否则，比较列表中的前两个元素，如果第一个小于等于第二个，就将第一个元素插入到对剩余元素进行递归分组的第一个子列表中的最前面；否则，创建一个只含有第一个元素的列表，接着对剩余的元素进行递归分组。
\end{itemize}

\be
group(L) =  \left \{
  \begin{array}
  {r@{\quad:\quad}l}
  \{ L \} & |L| \leq 1 \\
  \{ \{ l_1 \} \cup L_1, L_2, ... \} & l_1 \leq l_2, \{ L_1, L_2, ...\} = group(L') \\
  \{ \{ l_1 \}, L_1, L_2, ... \} & otherwise
  \end{array}
\right.
\ee

也可以将分组条件抽象成一个参数，传入一个通用的分组函数中。如下面的Haskell例子代码所示\footnote{虽然Haskell的标准库Data.List中包含一个\texttt{groupBy}函数。但是这里不能使用它。这是因为它接受一个相等测试函数作为参数，必须满足自反性、传递性和对称性。但是我们的比较条件为“小于等于”，并不满足对称性。具体可以参考本书附录A。}。

\lstset{language=Haskell}
\begin{lstlisting}[style=Haskell]
groupBy' :: (a->a->Bool) ->[a] ->[[a]]
groupBy' _ [] = [[]]
groupBy' _ [x] = [[x]]
groupBy' f (x:xs@(x':_)) | f x x' = (x:ys):yss
                         | otherwise = [x]:r
  where
    r@(ys:yss) = groupBy' f xs
\end{lstlisting}

和$sort$函数相比，$sort'$的参数不是一个待排序的元素列表，而是分组后的一系列子列表。

\be
sort'(\mathbb{L}) = \left \{
  \begin{array}
  {r@{\quad:\quad}l}
  \phi & \mathbb{L} = \phi \\
  L_1 & \mathbb{L} = \{ L_1 \} \\
  sort'(mergePairs(\mathbb{L})) & otherwise
  \end{array}
\right.
\ee

前两条是简单边界情况。如果待排序的子列表为空，则结果显然为空；如果仅含有一个子列表，则排序结束。这一子列表就是最终的排序结果；否则，我们调用函数$mergePairs$每两个子列表一组进行归并，然后递归地调用$sort'$函数。

接下来要定义$mergePairs$函数。顾名思义，它不断将成对的非递减子列表归并成更长的列表。

\be
mergePairs(L) = \left \{
  \begin{array}
  {r@{\quad:\quad}l}
  L & |L| \leq 1 \\
  \{ merge(L_1, L_2) \} \cup mergePairs(L'') & otherwise
  \end{array}
\right.
\ee

如果剩余的子列表少于两个，则处理结束；否则，我们首先将前两个子列表$L_1$和$L_2$归并，然后递归地将剩余在$L''$中的列表对归并。$mergePairs$的结果类型是列表的列表，最终$sort'$函数会将它们连接一个列表。

归并函数$merge$和此前的定义一致。下面的Haskell例子程序给出了完整的实现：

\lstset{language=Haskell}
\begin{lstlisting}[style=Haskell]
mergesort = sort' . groupBy' (<=)

sort' [] = []
sort' [xs] = xs
sort' xss = sort' (mergePairs xss) where
  mergePairs (xs:ys:xss) = merge xs ys : mergePairs xss
  mergePairs xss = xss
\end{lstlisting}

另外，我们可以先取出两个子列表，将它们归并为一个临时结果，然后不断取出下一个子列表，将其归并到临时结果中，直到所有剩余的子列表都归并完。这是一个典型的fold过程，详细介绍见附录A。

\be
sort(L) = fold(merge, \phi, group(L))
\ee

下面的Haskell例子程序实现了这一用fold定义的归并排序：

\lstset{language=Haskell}
\begin{lstlisting}[style=Haskell]
mergesort' = foldl merge [] . groupBy' (<=)
\end{lstlisting}

\begin{Exercise}
\begin{itemize}
  \item 使用fold实现的自然归并排序在性能上和使用$mergePairs$的算法相同么？如果相同，请给出证明；如果不同，哪个更快？
\end{itemize}
\end{Exercise}

\section{自底向上归并排序}
\index{归并排序!自底向上归并排序}

从自然归并排序的最差情况分析可以引出一个有趣的内容，归并排序既可以自顶向下进行，也可以自底向上进行。自底向上带来的最大好处是可以很方便地用迭代的方式实现。

为了实现自底向上归并排序，首先将待排序序列变成$n$个子列表，每个子列表只包含一个元素。然后我们将每两个相邻的子序列归并，这样就得到了$\frac{n}{2}$个长度为2的已序子序列；如果$n$是奇数，最后会剩余一个长度为1的子序列。我们重复将相邻的子序列对归并，最后就会得到排序的结果。Knuth将这种算法称为“直接两路归并排序”（straight two-way merge sort）\cite{TAOCP}。图\ref{fig:bottom-up-msort}描述了自底向上的归并排序。

\begin{figure}[htbp]
 \centering
 \includegraphics[scale=0.6]{img/bottom-up-msort}
 \caption{自底向上归并排序}
 \label{fig:bottom-up-msort}
\end{figure}

和基本归并排序算法以及奇偶归并排序算法不同，我们无需在每次递归时分割列表。整个列表在一开始时被分为$n$个只有一个元素的子列表，然后接下来不断对它们进行归并。

\be
sort(L) = sort'(wraps(L))
\ee

\be
wraps(L) = \left \{
  \begin{array}
  {r@{\quad:\quad}l}
  \phi & L = \phi \\
  \{ \{l_1\} \} \cup wraps(L') & otherwise
  \end{array}
\right.
\ee

当然$wraps$也可以使用map来实现，具体参见附录A。

\be
sort(L) = sort'(map(\lambda_x \cdot \{ x \}, L))
\ee

我们可以复用自然归并排序中定义的$sort'$函数和$mergePairs$函数。不断成对归并子列表，直到最后只剩下一个列表。

下面的Haskell例子程序实现了这一算法。

\lstset{language=Haskell}
\begin{lstlisting}[style=Haskell]
sort = sort' . map (\x->[x])
\end{lstlisting}

这一算法基于Okasaki在\cite{okasaki-book}中给出结果。他和自然归并排序非常类似，仅仅是分组的方法不同。本质上，它可以由自然归并排序的一种特殊情况（最差情况）推导出来：

\be
sort(L)= sort'(groupBy(\lambda_{x, y} \cdot False, L))
\ee

自然归并排序总是将非递减子列表扩展到最长，与此不同，这里的判断条件永远是False，因此子列表的长度仅扩展到1个元素。

和自然归并排序类似，自底向上归并排序也可以用fold来定义。具体的实现留给读者作为练习。

观察自底向上归并排序，它已经是尾递归形式了，可以很容易地消除递归，转换成纯迭代算法。

\begin{algorithmic}[1]
\Function{Sort}{$A$}
  \State $B \gets \phi$
  \For{$\forall a \in A$}
    \State $B \gets$ \Call{Append}{$\{ a \}$}
  \EndFor
  \State $N \gets |B|$
  \While{$N > 1$}
    \For{$i \gets $ from $1$ to $\lfloor \frac{N}{2} \rfloor$}
      \State $B[i] \gets$ \Call{Merge}{$B[2i -1], B[2i]$}
    \EndFor
    \If{\Call{Odd}{$N$}}
      \State $B[\lceil \frac{N}{2} \rceil] \gets B[N]$
    \EndIf
    \State $N \gets \lceil \frac{N}{2} \rceil$
  \EndWhile
  \If{$B = \phi$}
    \State \Return $\phi$
  \EndIf
  \State \Return $B[1]$
\EndFunction
\end{algorithmic}

下面的Python例子程序实现了纯迭代式的自底向上归并排序。

\lstset{language=Python}
\begin{lstlisting}
def mergesort(xs):
    ys = [[x] for x in xs]
    while len(ys) > 1:
        ys.append(merge(ys.pop(0), ys.pop(0)))
    return [] if ys == [] else ys.pop()

def merge(xs, ys):
    zs = []
    while xs != [] and ys !=[]:
        zs.append(xs.pop(0) if xs[0] < ys[0] else ys.pop(0))
    return zs + (xs if xs !=[] else ys)
\end{lstlisting}

和上面的伪代码相比，它每次从头部取出一对子列表，归并好后追加到尾部。这样就极大地简化了奇数个子列表的处理。

\begin{Exercise}
\begin{itemize}
\item 使用fold实现函数式的自底向上归并排序。
\item 只使用数组下标，实现迭代式的自底向上归并排序。不要使用标准库中提供的工具，如list或vector等。
\end{itemize}
\end{Exercise}

\section{并行处理}
\index{并行归并排序}
\index{并行快速排序}

在基本快速排序的算法中，当划分完成时，可以并行对两个子序列进行排序。这一策略对归并排序也适用。实际上，并行的快速排序和归并排序算法，并不只使用两个并行的任务对划分好的子序列排序，而是将序列分割成$p$个子序列，其中$p$为处理器的个数。理想情况下，如果我们可以并行在$T'$时间内完成排序，并且满足$O(n \lg n) = p T'$，就称为“线性加速”(linear speed up)，这样的算法叫做最优化并行算法。

但是，简单地扩展基本快速排序算法，选取$p-1$个pivot，划分为$p$个子序列，然后并行对它们排序，并不是最优化的。瓶颈出现在划分阶段，我们只能得到平均$O(n)$的性能。

另一方面，简单地将基本归并排序算法扩展为并行时，瓶颈出现在归并阶段。为了达到最优化的并行加速，需要对并行的归并排序和快速排序进行更好的设计。实际上，归并排序和快速排序的分而治之特性使得它们相对容易进行并行化。Richard Cole在1986年发现了使用$n$个处理器，性能为$O(\lg n)$的并行归并排序算法\cite{para-msort}。

并行处理是一个巨大而复杂的题目，超出了本书描述“基本算法”的范围。读者可以参考\cite{para-msort}和\cite{para-qsort}了解更详细的内容。

\section{小结}

本章介绍了两种常用的分而治之排序算法：快速排序和归并排序。它们都达到了基于比较的排序算法的性能上限$O(n \lg n)$。Sedgewick评价快速排序是20世纪发现的最伟大的算法。大量的编程环境都使用快速排序作为内置的排序工具。随着时间推移，某些环境中，特别是那些需要处理动态抽象序列的情况下，序列的模型往往不是简单的数组，它们逐渐转而使用归并排序作为通用的排序工具\footnote{实际中，大部分排序工具都是某种混合算法，在序列较短时使用插入排序来保持良好的性能}。

这一现象的原因，可以部分地在本章中找到解释。快速排序在大多数情况下表现优异。它主要依靠交换操作，和其他算法相比，快速排序需要较少的交换操作。但是在纯函数环境中，交换并不是最有效的操作，这是因为底层的数据结构通常是单向链表，而不是向量化的数组。另一方面，归并排序则很适合这类环境，它不需要额外的空间，并且即使在快速排序遇到的最坏情况下，也能保证性能。反之快速排序的性能这时就会退化到平方级别。但是在命令式环境中，归并排序不如快速排序在处理数组时的性能表现。它要么需要额外的空间进行归并，要么需要更多的交换操作作为代价。但在某些情况下无法保证有足够的空间可用，例如在嵌入式系统中，内存往往受到限制。目前，原地归并排序仍然是一个活跃的研究领域。

虽然本章的题目叫做“快速排序和归并排序”，但这并不是说这两种排序彼此无关。快速排序可以被看作树排序的一种优化形式。同样归并排序也可以由树排序推导出来\cite{sort-deriving}。

存在多种对排序算法的分类，常见的如\cite{TAOCP}，另外一种是根据划分的难易程度和归并的难易程度分类\cite{algo-fp}。

例如快速排序，它的归并很容易，因为pivot前的子序列中的所有元素，都小于等于pivot后子序列中的任意元素。快速排序的归并过程实际上就是序列的简单连接。

与此相反，归并排序的归并过程要比快速排序复杂得多。但是划分过程却很简单。无论是等分成两个子序列、奇偶分割、自然分割、还是自底向上分割。和归并排序相比，快速排序很难保证完美分割。我们在理论上证明了，快速排序无法完全避免最差情况，尽管人们想出一些工程实践方法如median-of-three，随机快速排序，以及三路划分等。

到本章为止，我们给出了一些基本的排序算法，包括插入排序、树排序、选择排序、堆排序、快速排序和归并排序。排序仍然是计算机科学中活跃的研究领域。在写这一章的时候，人们正经历着当时所谓“大数据”（big data）的挑战，传统的排序方法无法在有限的时间和资源下处理越来越巨大的数据。在某些领域，处理几百G的数据已经成为了日常工作中的任务。

\begin{Exercise}
  \begin{itemize}
    \item 使用归并排序的策略，设计一种算法可以从一个序列产生一棵二叉搜索树。
  \end{itemize}
\end{Exercise}

\section{附录：例子程序}

原地划分：

\begin{lstlisting}[language = Bourbaki]
Int partition(K[] xs, Int l, Int u) {
    for (Int pivot = l, Int r = l + 1; r < u; r = r + 1) {
        if xs[pivot] >= xs[r] {
            l = l + 1
            swap(xs[l], xs[r])
        }
    }
    swap(xs[pivot], xs[l])
    return l + 1
}

void sort(K[] xs, Int l, Int u) {
    if l < u {
        Int m = partition(xs, l, u)
        sort(xs, l, m - 1)
        sort(xs, m, u)
    }
}
\end{lstlisting}

双向扫描：

\begin{lstlisting}[language = Bourbaki]
void sort(K[] xs, Int l, Int u) {
    if l < u - 1 {
        Int pivot = l, Int i = l, Int j = u
        loop {
            while i < u and xs[i] < xs[pivot] {
                i = i + 1
            }
            while j >=l and xs[pivot] < xs[j] {
                j = j - 1
            }
            if j < i then break
            swap(xs[i], xs[j])
        }
        swap(xs[pivot], xs[j])
        sort(xs, l, j)
        sort(xs, i, u)
    }
}
\end{lstlisting}

归并排序：

\begin{lstlisting}[language = Bourbaki]
K[] sort(K[] xs) {
    Int n = length(xs)
    if n > 1 {
        var ys = sort(xs[0 ... n/2 - 1])
        var zs = sort(xs[n/2 ...])
        xs = merge(xs, ys, zs)
    }
    return xs
}

K[] merge(K[] xs, K[] ys, K[] zs) {
    Int i = 0
    while ys != [] and zs != []:
        xs[i] = if ys[0] < zs[0] then ys.pop(0) else zs.pop(0)
        i = i + 1
    xs[i...] = if ys !=[] then ys else zs
    return xs
}
\end{lstlisting}

\ifx\wholebook\relax\else

\begin{thebibliography}{99}

\bibitem{TAOCP}
Donald E. Knuth. ``The Art of Computer Programming, Volume 3: Sorting and Searching (2nd Edition)''. Addison-Wesley Professional; 2 edition (May 4, 1998) ISBN-10: 0201896850 ISBN-13: 978-0201896855

\bibitem{CLRS}
Thomas H. Cormen, Charles E. Leiserson, Ronald L. Rivest and Clifford Stein.
``Introduction to Algorithms, Second Edition''. ISBN:0262032937. The MIT Press. 2001

\bibitem{qsort-impl}
Robert Sedgewick. ``Implementing quick sort programs''. Communication of ACM. Volume 21, Number 10. 1978. pp.847 - 857.

\bibitem{Bentley}
Jon Bentley. ``Programming pearls, Second Edition''. Addison-Wesley Professional; 1999. ISBN-13: 978-0201657883

\bibitem{3-way-part}
Jon Bentley, Douglas McIlroy. ``Engineering a sort function''. Software Practice and experience VOL. 23(11), 1249-1265 1993.

\bibitem{opt-qs}
Robert Sedgewick, Jon Bentley. ``Quicksort is optimal''. \url{http://www.cs.princeton.edu/~rs/talks/QuicksortIsOptimal.pdf}

\bibitem{fp-pearls}
Richard Bird. ``Pearls of functional algorithm design''. Cambridge University Press. 2010. ISBN, 1139490605, 9781139490603

\bibitem{algo-fp}
Fethi Rabhi, Guy Lapalme. ``Algorithms: a functional programming approach''. Second edition. Addison-Wesley, 1999. ISBN: 0201-59604-0

\bibitem{slpj-book-1987}
Simon Peyton Jones. ``The Implementation of functional programming languages''. Prentice-Hall International, 1987. ISBN: 0-13-453333-X

\bibitem{msort-in-place}
Jyrki Katajainen, Tomi Pasanen, Jukka Teuhola. ``Practical in-place mergesort''. Nordic Journal of Computing, 1996.

\bibitem{okasaki-book}
Chris Okasaki. ``Purely Functional Data Structures''. Cambridge university press, (July 1, 1999), ISBN-13: 978-0521663502

\bibitem{sort-deriving}
Jos\`{e} Bacelar Almeida and Jorge Sousa Pinto. ``Deriving Sorting Algorithms''. Technical report, Data structures and Algorithms. 2008.

\bibitem{para-msort}
Cole, Richard (August 1988). ``Parallel merge sort''. SIAM J. Comput. 17 (4): 770-785. doi:10.1137/0217049. (August 1988)

\bibitem{para-qsort}
Powers, David M. W. ``Parallelized Quicksort and Radixsort with Optimal Speedup'', Proceedings of International Conference on Parallel Computing Technologies. Novosibirsk. 1991.

\bibitem{wiki-qs}
Wikipedia. ``Quicksort''. \url{https://en.wikipedia.org/wiki/Quicksort}

\bibitem{wiki-sweak-order}
Wikipedia. ``Strict weak order''. \url{https://en.wikipedia.org/wiki/Strict_weak_order}

\bibitem{wiki-total-order}
Wikipedia. ``Total order''. \url{http://en.wokipedia.org/wiki/Total_order}

\bibitem{wiki-harmonic}
Wikipedia. ``Harmonic series (mathematics)''. \url{https://en.wikipedia.org/wiki/Harmonic_series_(mathematics)}

\end{thebibliography}

\expandafter\enddocument
\fi
