\ifx\wholebook\relax \else

\documentclass[b5paper]{article}
\usepackage[nomarginpar
  %, margin=.5in
]{geometry}

\addtolength{\oddsidemargin}{-0.05in}
\addtolength{\evensidemargin}{-0.05in}
\addtolength{\textwidth}{0.1in}
\usepackage[en]{../../prelude}

\setcounter{page}{1}

\begin{document}

\title{Selection sort}

\author{Xinyu LIU
\thanks{{\bfseries Xinyu LIU} \newline
  Email: liuxinyu95@gmail.com \newline}
  }

\maketitle
\fi

\markboth{Selection sort}{Elementary Algorithms}

\ifx\wholebook\relax
\chapter{Selection sort}
\numberwithin{Exercise}{chapter}
\fi

\section{Introduction}
\label{introduction} \index{selection sort}
\lstset{frame = single}

Selection sort is a straightforward sorting algorithm. It repeatedly selects the minimum (or maximum) from a collection of elements. It performs below the divide and conqueror sort algorithms, like quick sort and merge sort. We'll give different ways to improve it, and finally evolve it to heap sort, achieving $O(n \lg n)$, the upper limit of comparison based sort algorithm time bound. When facing a bunch of grapes, there are two types of kids. One pick the biggest grape to eat every time, the other always eat the smallest one. The first type eats the grape in ascending order of size, the other eats in descending order. In either case, the kid essentially applies selection sort method. It can be defined as:

\begin{enumerate}
\item If the collection is empty, the sorted result is empty;
\item Otherwise, select the minimum element, and append it to the sorted result.
\end{enumerate}

It sorts elements in ascending order. We can obtain descending order by selecting the maximum. The compare operation can be abstract.

\be
\begin{array}{rcl}
sort\ [\ ]  & = & [\ ] \\
sort\ A & = & m : sort\ (A - [m]) \quad \text{where}\ m = min\ A
\end{array}
\ee

Where $A - [m]$ is the remaining elements in $A$ except $m$. The corresponding imperative implementation is as below:

\begin{algorithmic}[1]
\Function{Sort}{$A$}
  \State $X \gets [\ ]$
  \While{$A \neq [\ ]$}
    \State $x \gets$ \Call{Min}{$A$}
    \State \Call{Del}{$A, x$}
    \State \Call{Append}{$X, x$}
  \EndWhile
  \State \Return $X$
\EndFunction
\end{algorithmic}

\begin{figure}[htbp]
  \centering
  \includegraphics[scale=0.8]{img/ssort}
  \caption{The left is sorted, repeatedly select the minimum of the rest and append.}
  \label{fig:sel-sort}
\end{figure}

Figure \ref{fig:sel-sort} shows the process of selection sort. We can improve it to in-place sort. The idea is to reuse $A$. Place the minimum element in $A[1]$, the second smallest one in $A[2]$, ...When find the $i$-th smallest element, swap it with $A[i]$.

\begin{algorithmic}[1]
\Function{Sort}{$A$}
  \For{$i \gets 1$ to $|A|$}
    \State $m \gets$ \Call{Min-At}{$A, i$}
    \State \textproc{Exchange} $A[i] \leftrightarrow A[m]$
  \EndFor
\EndFunction
\end{algorithmic}

Let $A = [a_1, a_2, ..., a_n]$, when select the $i$-th smallest element, $[a_1, a_2, ..., a_{i-1}]$ are sorted. We find the minimum of $[a_i, a_{i+1}, ..., a_n]$, and swap it with $a_i$. Repeat this to process all elements as shown in figure \ref{fig:in-place-ssort}.

\begin{figure}[htbp]
  \centering
  \begin{tikzpicture}[scale=0.8]
    \draw (0, 0) rectangle (3.5,1) node[pos=.5] {... sorted ...};
    \draw (4, 0) rectangle (5, 1) node (x) [pos=.5] {$x$};
    \draw (5, 0) rectangle (6, 1) node[pos=.5] {...};
    \draw (6, 0) rectangle (7, 1) node (min) [pos=.5] {$min$};
    \draw (7, 0) rectangle (8, 1) node[pos=.5] {...};
    \draw[thick, <->] (x) edge[bend left=45] node [above] {swap} (min);
  \end{tikzpicture}
  \caption{The left is sorted, repeatedly find the minimum and swap to the right position.}
  \label{fig:in-place-ssort}
\end{figure}

\section{Find the minimum}
\index{selection sort!min}

We can use the `compare and swap' method to find the minimum element. Label the elements with $1, 2, ..., n$. Compare the elements of number 1 and 2, pick the smaller and compare it with number 3, ... repeat till the last element of number $n$.

\begin{algorithmic}[1]
\Function{Min-At}{$A, i$}
  \State $m \gets i$
  \For{$i \gets m + 1 $ to $|A|$}
    \If{$A[i] < A[m]$}
      \State $m \gets i$
    \EndIf
  \EndFor
  \State \Return $m$
\EndFunction
\end{algorithmic}

The \textproc{Min-At} find the minimum $m$ from slice $A[i...]$. Let $m$ start pointing to $A[i]$, then scan $A[i+1], A[i+2], ...$.

\index{selection sort!tail-recursive min}
We can also find the minimum from list of elements $L$ recursively. When $L$ is a singleton, the only element is the minimum; otherwise pick an element $x$ from $L$, then recursively find the minimum $y$ from the remaining, the smaller one between $x$ and $y$ is the minimum of $L$.

\be
\begin{array}{rcl}
min\ [x] & = & (x, [\ ]) \\
min\ (x:xs) & = & \begin{cases}
  x < y: & (x, xs),\ \text{where}\ (y, ys) = min\ xs \\
  \text{otherwise}: & (y,\ x:ys)
\end{cases}
\end{array}
\ee


We can further improve it tail recursively. Divide the elements with two groups $A$ and $B$. $A$ is initialized empty ($[\ ]$), $B$ contains all elements. We pick two elements from $B$, compare and put the greater one to $A$, leave the smaller one as $m$. Then repeatedly pick element from $B$, compare with $m$ till $B$ becomes empty. Finally, $m$ is the minimum element. At any time, we have the invariant: $L = A \doubleplus [m] \doubleplus B$, where $a \leq m \leq b, a \in A, b \in B$.

\be
min\ (x:xs) = min'\ [\ ]\ x\ xs
\ee

Where:

\be
\begin{array}{rcl}
min'\ as\ m\ [\ ] & = & (m, A) \\
min'\ as\ m\ (b:bs) & = & \begin{cases}
  b < m: & min'\ (m:as)\ b\ bs \\
  \text{otherwise}: & min'\ (b:as)\ m\ bs \\
\end{cases}
\end{array}
\ee

Function $min$ return a pair: the minimum and the remaining elements. We can define selection sort as below:

\be
\begin{array}{rcl}
sort\ [\ ] & = & [\ ] \\
sort\ xs   & = & m : (sort\ xs'),\ \text{where}\ (m, xs') = min\ xs \\
\end{array}
\ee

\subsection{Performance}

Selection sort need scan the unsorted elements to find the minimum for $n$ times. It compares $n + (n-1) + (n-2) + ... + 1$ times. The time bound is $O(\dfrac{n(n+1)}{2}) = O(n^2)$. Compare to the insertion sort, selection sort performs same in the best, worst, and average cases. While insertion sort performs best at $O(n)$ (the linked-list is in reversed ordered), and worst at $O(n^2)$.

\begin{Exercise}
\Question{What is the problem with below implementation of $min$?
\[
\begin{array}{rcl}
min'\ as\ m\ [\ ] & = & (m, A) \\
min'\ as\ m\ (b:bs) & = & \begin{cases}
  b < m: & min'\ (as \doubleplus [m])\ b\ bs \\
  \text{否则}: & min'\ (as \doubleplus [b])\ m\ bs \\
\end{cases}
\end{array}
\]
}
\Question{Implement the selection sort for both in-placed and not.}
\end{Exercise}

\begin{Answer}
\Question{We should use link but not append. Appending is linear to the length of the list, while linking is constant time.}
\Question{Implement the selection sort for both in-placed and not. TO-DO}
\end{Answer}

\section{Improvement}

To sort in ascending, descending, and varies of ordering, we abstract the comparison as $\lhd$.

\be
\begin{array}{rcl}
sortBy \lhd\ [\ ] & = & [] \\
sortBy \lhd\ xs & = & m : sortBy\ \lhd\ xs',\ \text{where}\ (m, xs') = minBy\ \lhd\ xs \\
\end{array}
\ee

We also use $\lhd$ to find the 'minimum':

\be
\begin{array}{rcl}
minBy\ \lhd\ [x] & = & (x, [\ ]) \\
minBy\ \lhd\ (x:xs) & = & \begin{cases}
  x \lhd y: & (x, xs),\ \text{where}\ (y, ys) = minBy\ xs \\
  \text{otherwise}: & (y,\ x:ys)
\end{cases}
\end{array}
\ee

For example, we pass the $<$ to sort a collection of numbers in ascending order: $sortBy\ (<)\ [3, 1, 4, ...]$. As the constraint, we need the comparison $\lhd$ satisfy the {\em strict weak order}\cite{wiki-sweak-order}.

\begin{itemize}
\item Irreflexivity: for all $x$, $x < x$ is false;
\item Asymmetry: for all $x$ and $y$, if $x < y$, then $y < x$ is false;
\item Transitivity, for all $x$, $y$, and $z$, if $x < y$, and $y < z$, then $x < z$.
\end{itemize}

The in-place selection sort traverses all elements, we can find the minimum as an inner loop to make the implementation compact:

\begin{algorithmic}[1]
\Procedure{Sort}{$A$}
  \For{ $i \gets 1$ to $|A|$}
    \State $m \gets i$
    \For{$j \gets i+1$ to $|A|$}
      \If{$A[i] < A[m]$}
        \State $m \gets i$
      \EndIf
    \EndFor
    \State \textproc{Exchange} $A[i] \leftrightarrow A[m]$
  \EndFor
\EndProcedure
\end{algorithmic}

After sort the first $n-1$ elements, the last one must be the maximum. We can save the last loop. Besides, we needn't swap if the $i$-th smallest is exactly $A[i]$.

\begin{algorithmic}[1]
\Procedure{Sort}{$A$}
  \For{ $i \gets 1$ to $|A|-1$}
    \State $m \gets i$
    \For{$j \gets i+1$ to $|A|$}
      \If{$A[i] < A[m]$}
        \State $m \gets i$
      \EndIf
    \EndFor
    \If{$m \neq i$}
      \State \textproc{Exchange} $A[i] \leftrightarrow A[m]$
    \EndIf
  \EndFor
\EndProcedure
\end{algorithmic}

\subsection{Cock-tail sort}
\index{Cock-tail sort}

Knuth gives another selection sort implementation\cite{TAOCP}. Select the maximum, but not the minimum, and move it to the tail, as shown in figure \ref{fig:knuth-ssort}. At any time, the right most part is sorted. We scan the unsorted part, find the maximum and swap to the right.

\begin{algorithmic}[1]
\Procedure{Sort'}{$A$}
  \For{ $i \gets |A|$ down-to $2$}
    \State $m \gets i$
    \For{$j \gets 1$ to $i-1$}
      \If{$A[m] < A[i]$}
        \State $m \gets i$
      \EndIf
    \EndFor
    \State \textproc{Exchange} $A[i] \leftrightarrow A[m]$
  \EndFor
\EndProcedure
\end{algorithmic}

\begin{figure}[htbp]
  \centering
  \begin{tikzpicture}[scale=0.8]
    \draw (5, 0) rectangle (6, 1) node[pos=.5] {...};
    \draw (6, 0) rectangle (7, 1) node (max) [pos=.5] {$max$};
    \draw (7, 0) rectangle (8, 1) node[pos=.5] {...};
    \draw (8, 0) rectangle (9, 1) node (x) [pos=.5] {$x$};
    \draw (10,0) rectangle (13.5,1) node[pos=.5] {... sorted ...};
    \draw[thick, <->] (x) edge[bend right=45] node [above] {swap} (max);
  \end{tikzpicture}
  \caption{Select the maximum and swap to tail}
  \label{fig:knuth-ssort}
\end{figure}

We obtain the ascending order as well. Further, we can pick both the minimum and maximum in one pass, swap the minimum to the head, and the maximum to the tail. We can halve the inner loop times. The method is called `cock-tail sort'.

\begin{algorithmic}[1]
\Procedure{Sort}{$A$}
  \For{$i \gets 1 $ to $\lfloor \dfrac{|A|}{2} \rfloor$}
    \State $min \gets i$
    \State $max \gets |A| + 1 - i$
    \If{$A[max] < A[min]$}
      \State \textproc{Exchange} $A[min] \leftrightarrow A[max]$
    \EndIf
    \For{$j \gets i + 1$ to $|A| - i$}
      \If{$A[j] < A[min]$}
        \State $min \gets j$
      \EndIf
      \If{$A[max] < A[j]$}
        \State $max \gets j$
      \EndIf
    \EndFor
    \State \textproc{Exchange} $A[i] \leftrightarrow A[min]$
    \State \textproc{Exchange} $A[|A|+1-i] \leftrightarrow A[max]$
  \EndFor
\EndProcedure
\end{algorithmic}

\begin{figure}[htbp]
  \centering
  \begin{tikzpicture}[scale=0.8]
    \draw (0,0) rectangle (3.5,1) node[pos=.5] {... sorted smaller ...};
    \draw (4, 0) rectangle (5, 1) node (x) [pos=.5] {$x$};
    \draw (5, 0) rectangle (6, 1) node[pos=.5] {...};
    \draw (6, 0) rectangle (7, 1) node (max) [pos=.5] {$max$};
    \draw (7, 0) rectangle (8, 1) node[pos=.5] {...};
    \draw (8, 0) rectangle (9, 1) node (min) [pos=.5] {$min$};
    \draw (9, 0) rectangle (10, 1) node[pos=.5] {...};
    \draw (10, 0) rectangle (11, 1) node (y) [pos=.5] {$y$};
    \draw (12,0) rectangle (15.5,1) node[pos=.5] {... sorted greater ...};
    \draw[thick, <->] (x) edge[bend right=45] node [below] {swap} (min);
    \draw[thick, <->] (y) edge[bend right=45] node [above] {swap} (max);
  \end{tikzpicture}
  \caption{Find the minimum and maximum, swap both to the right positions.}
  \label{fig:cock-tail-sort}
\end{figure}

It's necessary to swap if the right most element less than the right most one before the inner loop. This is because the scan excludes them. We can also implement the cock-tail sort recursively:

\begin{enumerate}
  \item If the list is empty or singleton, it's sorted;
  \item Otherwise, we select the minimum and the maximum, move them  to the head and tail, then recursively sort the rest elements.
\end{enumerate}

\be
\begin{array}{rcl}
sort\ [\ ] & = & [\ ] \\
sort\ [x] & = & [x] \\
sort\ xs & = & a : (sort\ xs') \doubleplus [b], \text{where}\ (a, b, xs') = \textit{minMax}\ xs \\
\end{array}
\ee

Where function \textit{minMax} extracts the minimum and maximum from a list:

\be
\textit{minMax}\ (x:y:xs) = foldr\ sel (min\ x\ y, max\ x\ y, [\ ])\ xs
\ee

We initialize the minimum as the first element $x_0$, and the maximum as the second element $x_1$, and process the list with $foldr$. Function $sel$ is defined as:

\[
sel\ x\ (x_0, x_1, xs) = \begin{cases}
  x < x_0: & (x, x_1, x_0 : xs) \\
  x_1 < x: & (x_0, x, x_1 : xs) \\
  \text{otherwsie}: & (x_0, x_1, x : xs) \\
\end{cases}
\]

Although \textit{minMax} is bound to $O(n)$ time, $\doubleplus[b]$ is expensive. As shown in figure \ref{fig:cock-tail-sort}, let the left sorted part be $A$, the right sorted part be $B$. We can turn the cock-tail sort to tail recursive with $A$ and $B$ as the accumulators.

\be
\begin{array}{rcl}
sort'\ A\ B\ [\ ] & = & A \doubleplus B \\
sort'\ A\ B\ [x]  & = & A \doubleplus (x:B) \\
sort'\ A\ B\ (x:xs) & = & sort'\ (A \doubleplus [x_0])\ xs'\ (x_1:B) \\
\end{array}
\ee

Where $(x_0, x_1, xs') = \textit{minMax}\ xs$. We pass empty $A$ and $B$ to initialize sorting: $sort = sort'\ [\ ]\ [\ ]$. The append only happens to $A \doubleplus [x_0]$, while $x_1$ is linked before $B$. Every recursion performs an append operation. To eliminate it, we can maintain $A$ in reversed order: $\overleftarrow{A}$, hence $x_0$ is linked ahead but appended. We have the following equations:

\be
\begin{array}{rcl}
A' & = & A \doubleplus [x] \\
   & = & reverse\ (x : reverse\ A) \\
   & = & reverse\ (x : \overleftarrow{A}) \\
   & = & \overleftarrow{ x : \overleftarrow{A}}
\end{array}
\ee

Finally, we reverse $\overleftarrow{A'}$ back to $A'$. We can improve the algorithm as below:

\be
\begin{array}{rcl}
sort'\ A\ B\ [\ ] & = & (reverse\ A) \doubleplus B \\
sort'\ A\ B\ [x]  & = & (reverse\ x:A) \doubleplus B \\
sort'\ A\ B\ (x:xs) & = & sort'\ (x_0:A)\ xs'\ (x_1:B) \\
\end{array}
\ee

\section{Further improvement}

Although cock-tail sort halves the loops, it's still bound to $O(n^2)$ time. To sort by comparison, we need the outer loop to examine all the elements for ordering. Do we need scan all the elements to select the minimum every time? After find the first smallest one, we've traversed the whole collection, obtain some information, like which are greater, which are smaller. However, we discard such information for further selection, but restart a fresh scan. The idea is information reusing. Let's see one inspired from football match.

\subsection{Tournament knock out}
\index{Tournament knock out}

The football world cup is held every four years. There are 32 teams from different continent play the final games. Before 1982, there were 16 teams in the finals. Let's go back to 1978 and imagine a special way to determine the champion: In the first round, the teams
are grouped into 8 pairs to play. There will be 8 winners, and 8 teams will be out. Then in the second round, 8 teams are grouped into 4 pairs. There will be 4 winners. Then the top 4 teams are grouped into 2 pairs, there will be two teams left for the final. The champion is determined after 4 rounds of games. There are total $8 + 4 + 2 + 1 = 15$ games. Besides the champion, we also want to know which is the silver medal team. In the real world cup, the team lost the final is the runner-up. However, it isn't fair in some sense. We often hear about the `group of death'. Suppose Brazil is grouped with Germam in round one. Although both teams are strong, one team is knocked out. It's quite possible that team would beat other teams except for the champion, as shown in figure \ref{fig:tournament-tree-1}.

\begin{figure}[htbp]
  \centering
  \includegraphics[scale=0.28]{img/tournament-tree-1}
  \caption{The element 15 is knocked out in the first round.}
  \label{fig:tournament-tree-1}
\end{figure}

Assign every team a number to measure its strength. Suppose the team with greater number always beats the smaller one (this is obviously not true in real world). The champion number is 16. the runner-up is not 14, but 15, which is out in the first round. We need figure out a way to quickly identify the second greater number in the tournament tree. The apply it to select the 3rd, the 4th, ... to sort. We can mutate the champion to a very small number, i.e. $-\infty$, hence it won't be selected next time, and the previous runner-up will become the new champion. For $2^m$ teams, where $m$ is some natural number, it takes $2^{m-1} + 2^{m-2} + ... + 2 + 1 = 2^m - 1$ comparisons to determine the new champion. This is same as before. Actually, we needn't perform bottom-up comparisons because the tournament tree
stores sufficient ordering information. The champion must beat the runner-up at sometime. We can locate the runner-up along the path from the root to the leaf of the champion. We grey the path in figure \ref{fig:tournament-tree-1} of $[14, 13, 7, 15]$. This method is defined as below:

\begin{enumerate}
\item Build a tournament tree with the maximum (the champion) at the root;
\item Take the root, replace it with $-\infty$ along the path to leaf;
\item Perform a bottom-up back-track along the path, find the new champion and store it in the root;
\item Repeat step 2 to process all elements.
\end{enumerate}

\captionsetup[subfigure]{labelformat=empty, margin=10pt}
\begin{figure}[htbp]
  \centering
  \subcaptionbox{Take 16, replace with $-\infty$, 15 becomes the new root.}{\includegraphics[scale=0.28]{img/tournament-tree-2}} \\
  \subcaptionbox{Take 15, replace with $-\infty$, 14 becomes the new root.}{\includegraphics[scale=0.28]{img/tournament-tree-3}} \\
  \subcaptionbox{Take 14, replace with $-\infty$, 13 becomes the new root.}{\includegraphics[scale=0.28]{img/tournament-tree-4}}
  \caption{The first 3 steps of tournament tree sort.}
  \label{fig:tournament-tree-4}
\end{figure}
\captionsetup[subfigure]{labelformat=parens}

To sort a collection of elements, we build a tournament tree from them, repeatedly select the champion from it. Figure \ref{fig:tournament-tree-4} gives the first 3 steps. We can re-use the binary tree definition. To make back-track easy, we need the parent field in each node. When $n$ is not $2^m$ form some natural number $m$, there is remaining element without ``player'', and directly enters the next round of games. To build the tournament tree, we build $n$ singleton trees from every element. Then pick every two $t_1$, $t_2$ to create a bigger binary tree $t$. Where the root of $t$ is $max(key(t_1), key(t_2))$, the left and right sub-trees are $t_1$, $t_2$. Repeat to obtain a collection of new trees, each height increases by one. If there is remaining, then enters the next round. After this round, trees halve to $\lfloor \dfrac{n}{2} \rfloor$. Repeat this to obtain the final tournament tree. The process is bound to $O(n + \dfrac{n}{2} + \dfrac{n}{4} + ... ) = O(2n) = O(n)$ time.

\begin{algorithmic}[1]
\Function{Build-Tree}{$A$}
  \State $T \gets [\ ]$
  \For{each $x \in A$}
    \State \textproc{Append}($T$, \Call{Node}{NIL, $x$, NIL})
  \EndFor
  \While{$|T| > 1$}
    \State $T' \gets [\ ]$
    \For{every $t_1, t_2 \in T$}
      \State $k \gets$ \textproc{Max}(\Call{Key}{$t_1$}, \Call{Key}{$t_2$})
      \State \textproc{Append}($T'$, \Call{Node}{$t_1$, $k$, $t_2$})
    \EndFor
    \If{|T| is odd}
      \State \textproc{Append}($T'$, \Call{Last}{$T$})
    \EndIf
    \State $T \gets T'$
  \EndWhile
  \State \Return $T[1]$
\EndFunction
\end{algorithmic}

We replace the root with $-\infty$ top-down, then back-track through the parent field to find the new maximum.

\begin{algorithmic}[1]
\Function{Pop}{$T$}
  \State $m \gets$ \Call{Key}{$T$}
  \State \Call{Key}{$T$} $\gets -\infty$
  \While{$T$ is not leaf}  \Comment{top-down replace $m$ with $-\infty$.}
    \If{\textproc{Key}(\Call{Left}{$T$}) $ = m$}
      \State $T \gets$ \Call{Left}{$T$}
    \Else
      \State $T \gets$ \Call{Right}{$T$}
    \EndIf
    \State \Call{Key}{$T$} $\gets -\infty$
  \EndWhile
  \While{\Call{Parent}{$T$} $\neq$ NIL} \Comment{bottom-up to find the new maximum.}
    \State $T \gets$ \Call{Parent}{$T$}
    \State \Call{Key}{$T$} $\gets$ \textproc{Max}(\textproc{Key}(\Call{Left}{$T$}), \textproc{Key}(\Call{Right}{$T$}))
  \EndWhile
  \State \Return $(m, T)$ \Comment{the maximum and the new tree.}
\EndFunction
\end{algorithmic}

\textproc{Pop} process the tree in two passes, top-down, then bottom-up along the path of the champion. Because the tournament tree is balanced, the length of this path, i.e. height of the tree, is bound to $O(\lg n)$, where $n$ is the number of the elements. Below is the tournament tree sort. We first build the tree in $O(n)$ time, then pop the maximum for $n$ times, each pop takes $O(\lg n)$ time. The total time is bound to $O(n \lg n)$.

\begin{algorithmic}
\Procedure{Sort}{$A$}
  \State $T \gets$ \Call{Build-Tree}{$A$}
  \For{$i \gets |A|$ down to $1$}
    \State $A[i] \gets$ \Call{Extract-Max}{$T$}
  \EndFor
\EndProcedure
\end{algorithmic}

\subsubsection{Refine the tournament knock out}
\index{Tounament knock out!explicit infinity}
It's possible to design the tournament knock out algorithm in purely functional approach. And we'll see
that the two passes (first top-down replace the champion with $-\infty$, then bottom-up determine the
new champion) in pop operation can be combined in recursive manner, so that we needn't the parent field
any more. We can re-use the functional binary tree definition as the following example Haskell code.

\lstset{language=Haskell}
\begin{lstlisting}
data Tr a = Empty | Br (Tr a) a (Tr a)
\end{lstlisting}

Thus a binary tree is either empty or a branch node contains a key, a left sub tree and a right sub tree.
Both children are again binary trees.

We've use hard coded big negative number to represents $-\infty$. However, this solution is ad-hoc, and
it forces all elements to be sorted are greater than this pre-defined magic number. Some programming
environments support algebraic type, so that we can define negative infinity explicitly. For instance,
the below Haskell program setups the concept of infinity \footnote{The order of the definition of `NegInf',
regular number, and `Inf' is significant if we want to derive the default, correct comparing behavior of `Ord'.
Anyway, it's possible to specify the detailed order by make it as an instance of `Ord'. However, this is
Language specific feature which is out of the scope of this book. Please refer to other textbook about Haskell.}.

\lstset{language=Haskell}
\begin{lstlisting}
data Infinite a = NegInf | Only a | Inf deriving (Eq, Ord)
\end{lstlisting}

From now on, we switch back to use the $min()$ function to determine the winner, so that the tournament selects the minimum
instead of the maximum as the champion.

Denote function $key(T)$ returns the key of the tree rooted at $T$. Function $wrap(x)$ wraps the element
$x$ into a leaf node. Function $tree(l, k, r)$ creates a branch node, with $k$ as the key, $l$ and $r$
as the two children respectively.

The knock out process, can be represented as comparing two trees, picking the smaller key as the new
key, and setting these two trees as children:

\be
branch(T_1, T_2) = tree(T_1, min(key(T_1), key(T_2)), T_2)
\ee

This can be implemented in Haskell word by word:

\lstset{language=Haskell}
\begin{lstlisting}
branch t1 t2 = Br t1 (min (key t1) (key t2)) t2
\end{lstlisting}

There is limitation in our tournament sorting algorithm so far. It only accepts collection of elements
with size of $2^m$, or we can't build a complete binary tree. This can be actually solved in the tree
building process. Remind that we pick two trees every time, compare and pick the winner. This is perfect
if there are always even number of trees. Considering a case in football match, that one team is absent
for some reason (sever flight delay or whatever), so that there left one team without a challenger.
One option is to make this team the winner, so that it will attend the further games. Actually, we can
use the similar approach.

To build the tournament tree from a list of elements, we wrap every element into a leaf, then start the
building process.

\be
build(L) = build'(\{wrap(x) | x \in L\})
\ee

The $build'(\mathbb{T})$ function terminates when there is only one tree left in $\mathbb{T}$, which
is the champion. This is the trivial edge case. Otherwise, it groups every two trees in a pair to determine
the winners. When there are odd numbers of trees, it just makes the last tree as the winner to attend the
next level of tournament and recursively repeats the building process.

\be
build'(\mathbb{T}) = \left \{
  \begin{array}
  {r@{\quad:\quad}l}
  \mathbb{T} & |\mathbb{T}| \leq 1 \\
  build'(pair(\mathbb{T})) & otherwise
  \end{array}
\right.
\ee

Note that this algorithm actually handles another special cases, that the list to be sort is empty.
The result is obviously empty.

Denote $\mathbb{T} = \{ T_1, T_2, ...\}$ if there are at least two trees, and $\mathbb{T}'$ represents
the left trees by removing the first two. Function $pair(\mathbb{T})$ is defined as the following.

\be
pair(\mathbb{T}) = \left \{
  \begin{array}
  {r@{\quad:\quad}l}
  \{ branch(T_1, T_2) \} \cup pair(\mathbb{T}') & |\mathbb{T}| \geq 2 \\
  \mathbb{T} & otherwise
  \end{array}
\right.
\ee

The complete tournament tree building algorithm can be implemented as the below example Haskell program.

\lstset{language=Haskell}
\begin{lstlisting}
fromList :: (Ord a) => [a] -> Tr (Infinite a)
fromList = build . (map wrap) where
  build [] = Empty
  build [t] = t
  build ts = build $ pair ts
  pair (t1:t2:ts) = (branch t1 t2):pair ts
  pair ts = ts
\end{lstlisting} %$

When extracting the champion (the minimum) from the tournament tree, we need examine either the left child
sub-tree or the right one has the same key as the root, and recursively extract on that tree until arrive at the leaf
node. Denote the left sub-tree of $T$ as $L$, right sub-tree as $R$, and $K$ as its key. We can define this popping
algorithm as the following.

\be
pop(T) =  \left \{
  \begin{array}
  {r@{\quad:\quad}l}
  tree(\phi, \infty, \phi) & L = \phi \land R = \phi \\
  tree(L', min(key(L'), key(R)), R) & K = key(L), L' = pop(L) \\
  tree(L, min(key(L), key(R')), R') & K = key(R), R' = pop(R)
  \end{array}
\right.
\ee

It's straightforward to translate this algorithm into example Haskell code.

\lstset{language=Haskell}
\begin{lstlisting}
pop (Br Empty _ Empty) = Br Empty Inf Empty
pop (Br l k r) | k == key l = let l' = pop l in Br l' (min (key l') (key r)) r
               | k == key r = let r' = pop r in Br l (min (key l) (key r')) r'
\end{lstlisting}

Note that this algorithm only removes the current champion without returning it. So it's necessary to
define a function to get the champion at the root node.

\be
top(T) = key(T)
\ee

With these functions defined, tournament knock out sorting can be formalized by using them.

\be
sort(L) = sort'(build(L))
\ee

Where $sort'(T)$ continuously pops the minimum element to form a result tree

\be
sort'(T) = \left \{
  \begin{array}
  {r@{\quad:\quad}l}
  \phi & T = \phi \lor key(T) = \infty \\
  \{ top(T) \} \cup sort'(pop(T)) & otherwise
  \end{array}
\right.
\label{eq:tsort}
\ee

The rest of the Haskell code is given below to complete the implementation.

\lstset{language=Haskell}
\begin{lstlisting}
top = only . key

tsort :: (Ord a) => [a] -> [a]
tsort = sort' . fromList where
    sort' Empty = []
    sort' (Br _ Inf _) = []
    sort' t = (top t) : (sort' $ pop t)
\end{lstlisting} %$

And the auxiliary function \texttt{only}, \texttt{key}, \texttt{wrap} accomplished with explicit infinity support are list
as the following.

\lstset{language=Haskell}
\begin{lstlisting}
only (Only x) = x
key (Br _ k _ ) = k
wrap x = Br Empty (Only x) Empty
\end{lstlisting}

\begin{Exercise}
  \begin{itemize}
    \item Implement the helper function \texttt{leaf()}, \texttt{branch}, \texttt{max()} \texttt{lsleaf()}, and \texttt{release()} to complete the imperative tournament tree program.
    \item Implement the imperative tournament tree in a programming language support GC (garbage collection).
    \item Why can our tournament tree knock out sort algorithm handle duplicated elements (elements with same value)? We say a sorting algorithm stable, if it keeps the original order of elements with same value. Is the tournament tree knock out sorting stable?
    \item Design an imperative tournament tree knock out sort algorithm, which satisfies the following:
      \begin{itemize}
        \item Can handle arbitrary number of elements;
        \item Without using hard coded negative infinity, so that it can take elements with any value.
      \end{itemize}
    \item Compare the tournament tree knock out sort algorithm and binary tree sort algorithm, analyze efficiency both in time and space.
    \item Compare the heap sort algorithm and binary tree sort algorithm, and do same analysis for them.
  \end{itemize}
\end{Exercise}

\subsection{Final improvement by using heap sort}

We manage improving the performance of selection based sorting to $O(n \lg n)$ by using tournament knock out.
This is the limit of comparison based sort according to \cite{TAOCP}. However, there are still rooms for improvement.
After sorting, there lefts a complete binary tree with all leaves and branches hold useless infinite values.
This isn't space efficient at all. Can we release the nodes when popping?

Another observation is that if there are $n$ elements to be sorted, we actually allocate about $2n$ tree nodes.
$n$ for leaves and $n$ for branches. Is there any better way to halve the space usage?

The final sorting structure described in equation \ref{eq:tsort} can be easily uniformed to a more general
one if we treat the case that the tree is empty if its root holds infinity as key:

\be
sort'(T) = \left \{
  \begin{array}
  {r@{\quad:\quad}l}
  \phi & T = \phi\\
  \{ top(T) \} \cup sort'(pop(T)) & otherwise
  \end{array}
\right.
\ee

This is exactly as same as the one of heap sort we gave in previous chapter.
Heap always keeps the minimum (or the maximum) on the top, and provides fast pop operation.
The binary heap by implicit array encodes the tree structure in array index, so there aren't
any extra spaces allocated except for the $n$ array cells. The functional heaps,
such as leftist heap and splay heap allocate $n$ nodes as well. We'll introduce more
heaps in next chapter which perform well in many aspects.

\section{Short summary}
In this chapter, we present the evolution process of selection based sort. selection
sort is easy and commonly used as example to teach students about embedded looping.
It has simple and straightforward structure, but the performance is quadratic.
In this chapter, we do see that there exists ways to improve
it not only by some fine tuning, but also fundamentally change the data
structure, which leads to tournament knock out and heap sort.

\begin{thebibliography}{99}

\bibitem{TAOCP}
Donald E. Knuth. ``The Art of Computer Programming, Volume 3: Sorting and Searching (2nd Edition)''. Addison-Wesley Professional; 2 edition (May 4, 1998) ISBN-10: 0201896850 ISBN-13: 978-0201896855

\bibitem{CLRS}
Thomas H. Cormen, Charles E. Leiserson, Ronald L. Rivest and Clifford Stein.
``Introduction to Algorithms, Second Edition''. ISBN:0262032937. The MIT Press. 2001

\bibitem{wiki-sweak-order}
Wikipedia. ``Strict weak order''. \url{https://en.wikipedia.org/wiki/Strict_weak_order}

\end{thebibliography}

\ifx\wholebook\relax\else
\end{document}
\fi
